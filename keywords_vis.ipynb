{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ale0xb/keywords-vis/blob/master/keywords_vis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-domain Visual Exploration of Academic Corpora via the Latent Meaning of User-authored Keywords (Full paper --> https://osf.io/h29qv/)\n",
    "## (Alejandro Benito, Roberto Therón) http://vis.usal.es\n",
    "## Abstract\n",
    "Nowadays, scholars dedicate a substantial amount of their work to querying and browsing increasingly large collections \n",
    "of research papers on the Internet. In parallel, the recent surge of novel interdisciplinary approaches in science requires \n",
    "scholars to acquire competencies in new fields for which they may lack the necessary vocabulary to formulate adequate queries. \n",
    "This problem, together with the issue of information overload, poses new challenges in the fields of natural language processing\n",
    "(NLP) and visualization design that call for a rapid response from the scientific community. In this respect, we report on a novel\n",
    "visualization scheme that enables the exploration of research paper collections via the analysis of semantic proximity relationships\n",
    "found in author-assigned keywords. Our proposal replaces traditional string queries by a bag-of-words (BoW) extracted from a \n",
    "user-generated auxiliary corpus that captures the intentionality of the research. Continuing on the line established by previous \n",
    "works, we combine novel advances in the fields of NLP with visual network analysis techniques to offer scholars a perspective of \n",
    "the target corpus that better fits their research needs. To highlight the advantages of our proposal, we conduct two experiments \n",
    "employing a collection of visualization research papers and an auxiliary cross-domain BoW. Here, we showcase how our visualization \n",
    "can be used to maximize the effectiveness of a browsing session by enhancing the language acquisition task, which allows an effective \n",
    "extraction of knowledge that is in line with the users’ previous expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QrK3t7nazjHB"
   },
   "source": [
    "## Google Colab only\n",
    "Uncomment the following two cells if you're running this notebook in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "7hsyeuCEFICk",
    "outputId": "8cd09376-1d2d-4e27-b9fc-56b9f86d4868"
   },
   "outputs": [],
   "source": [
    "#!pip install numpy==1.16.3 scipy==1.2.1 nltk==3.2.5 scikit-learn==0.20.3 iteration_utilities==0.7.0 networkx==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "_vmqaBCIoMCb",
    "outputId": "c42fc1b2-bfcf-4c3b-a5ae-8dc847267b96"
   },
   "outputs": [],
   "source": [
    "#!mkdir datasets\n",
    "#!mkdir model\n",
    "#!curl -O https://raw.githubusercontent.com/ale0xb/keywords-vis/master/datasets/dh_papers-complete.json \n",
    "#!curl -O https://raw.githubusercontent.com/ale0xb/keywords-vis/master/datasets/vispubdata_papers-2018-complete.json\n",
    "#!curl -O https://raw.githubusercontent.com/ale0xb/keywords-vis/master/model/all-paths.pkl\n",
    "  \n",
    "#!mv dh_papers-complete.json ./datasets\n",
    "#!mv vispubdata_papers-2018-complete.json ./datasets\n",
    "#!mv all-paths.pkl ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-NQEvyG3FZXF",
    "outputId": "bd747702-e32a-477c-f32c-6b034241bd42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alexb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "import scipy\n",
    "import scipy.sparse as sps\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy import stats\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "\n",
    "import shutil\n",
    "import pickle\n",
    "import itertools\n",
    "import copy\n",
    "from iteration_utilities import flatten\n",
    "import json\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POhXhgx7fWxJ"
   },
   "source": [
    "# Stem, unigrams, skipgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwPH8KXjjlFC"
   },
   "source": [
    "# Main method\n",
    "Our document exploration method comprises two main phases: The first involves all the necessary steps to generate a keyword-to-keyword similarity matrix from a latent semantic analysis of the corpus. The second phase focuses on the querying, filtering and visualization of this similarity matrix. As we introduced in previous sections, our method aims to remove the need to provide a textual query to extract knowledge from a given target corpus $C_{t}$ by relying instead on an auxiliary user-generated query corpus $C_{q}$. This distinction allows us to form two bags of words (BoW), formed by the keyword associations found in the query and target corpora, which are used as the two main inputs of our scheme. \n",
    "\n",
    "The query corpus can be freely composed from the user's reference manager or from any other source she or he considers relevant to study. Under this assumption, we expect the user to be familiar with the language of the query dataset whereas the target corpus is to be explored. At the end of the process, our method allows the user to query the target corpus by using keywords exclusive to the query corpus, effectively skipping the need for a language acquisition stage which may be highly time-consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "Before we continue to explain our proposed visualization scheme, in this section we comment on two document collections that were employed during our experiments. In the first sections, we discussed some of the problems related to the selection of an appropriate query string during the extraction phase of mapping studies and literature reviews, which we aimed to leverage in this work. To this end, we replace this query string with a bag-of-keywords (BOW) obtained from an auxiliary corpus. This first BOW represents the intentionality of the research; this is, it provides a high-level semantic expression that is representative of the kind of knowledge the researcher is interested in extracting from the target corpus. We construct this hypothetical situation in the context of two inherently interdisciplinary bodies of knowledge, DH and visualization, which we introduce below:\n",
    "\n",
    "## Query Corpus: Digital Humanities Visualization Papers\n",
    "\n",
    "DH is an interdisciplinary area of scholarly on which computational methods are applied in the resolution of research questions related to traditional humanities disciplines such as history, philosophy, linguistics, literature, art, archaeology, music, cultural studies and social sciences. This process usually involves the \"application of developed computational methods\"<cite data-cite=\"5825190/EPG46MXF\"></cite> in a variety of fields of computer science, such as topic modeling, digital mapping, text mining, information retrieval, digital publishing or visualization, in \"novel and unexpected ways\" <cite data-cite=\"5825190/EPG46MXF\"></cite>. Particularly, in recent years visualization has become a hot topic in DH as evidenced by the increasing number of visualization-related submissions to the annual DH conference. \n",
    "\n",
    "This surge has also had an impact on the visualization community, who have turned their attention to the DH as a vibrant new area of application for novel visualization techniques. An excellent example of this recent interest is the Workshop on Visualization for the DH [VIS4DH](http://vis4dh.dbvis.de/), which has taken place as a parallel session to the IEEE Vis Conference since its first edition in 2016. One of the recurrent discussions of this workshop has orbited around the idea of how to produce significant visualization advances in the context of the DH. Whereas visualization techniques have been showcased in a large number of computing problems related to the humanities, some authors have warned of an increasing tendency in the DH visualization community to apply standard visualization techniques (such as force-directed graph layouts or word clouds) to the resolution of intrinsically distinct research questions. This tendency, as these authors note, might be impeding the production of valuable visualization research in the humanities <cite data-cite=\"5825190/SFVYGKHS\"></cite> <cite data-cite=\"5825190/GGZM7TH4\"></cite> and therefore they stress the need to incorporate appropriate methodologies and evaluation techniques into the design process of the humanities.\n",
    "\n",
    "### Description\n",
    "According to the context presented in the previous paragraphs, the first dataset was constructed from metadata describing papers published in the DH conferences between years 2015-2018 <cite data-cite=\"5825190/2GKEGQL9\"></cite>. Given the broad range of themes present in this conference, we limited our search to papers that fell in the domain of visualization, i.e., papers that contained the word \"visualization\" either on its title, subject or any of its keywords. We also completed this data with author keywords associations extracted from papers presented at the three editions of the Workshops on Visualization for the DH between years 2016-2018. This composition ensures that we have a varied and rich BoW to query a larger, general-purpose target corpus. \n",
    "\n",
    "**The humanities-visualization dataset accounts for 257 documents, containing 728 unique keywords that appear a total of 1131 times, which gives an average of 4.40 keywords per paper.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_papers = json.loads(open('./datasets/dh_papers-complete.json').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Corpus: Data Visualization Research Papers\n",
    "The second document collection is related to the general topic of visualization. Visualization is a major research theme in computer science that relates to the generation of graphics, diagrams, images and animations that help to enhance the comprehensibility of the underlying data and computational algorithms at play in a broad range of computer-related domains. For these reasons, visualization research papers provide a rich and variate set of keyword associations to explore and to connect to other different knowledge domains (e.g. the humanities).\n",
    "The dataset comprises of meta-data from more than 3000 research papers presented at the IEEE Visualization set of conferences: InfoVis, SciVis, VAST and Vis from 1990-2018 and it was recently compiled by a group of experts in visualization <cite data-cite=\"5825190/NKZVXPYC\"></cite>. The dataset is publicly accessible https://vispubdata.org and actively maintained and updated by its authors. Data visualization research papers represent a rich corpus with multiple connections to other fields of modern science such as astronomy, sports, humanities, biology and machine learning, among others. \n",
    "\n",
    "**To date, the dataset contains 3102 research papers, of which 2123 contain author keywords. The number of unique keywords in this dataset is 5108, appearing a total of 9877 times, which results in an average of 4.64 keywords per paper.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_papers = json.loads(open('./datasets/vispubdata_papers-2018-complete.json').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIeols4kktE0"
   },
   "source": [
    "## Preprocessing\n",
    "Prior application of the semantic model to our data, we perform tokenization and stemming on the author-assigned keywords. In the tokenization process we split each multi-term keyword into its constituent parts, which are then stemmed and ultimately added to the BoW. Note that tokens appearing twice or more in the same document were counted as one. \n",
    "\n",
    "We noticed that in our case the inclusion of these two word pre-processing techniques was highly beneficial for the following reasons: The first and most obvious is that it provides an automated manner to match a high number of different linguistic keyword variations of the same concept (e.g. singular and plural), a circumstance that, unlike it occurs in keyword taxonomies, can be observed in uncontrolled keywords due to their closer proximity to natural language. Second, it allows the detection and subsequent removal of embedded stop words: this is, words that do not carry any real meaning in the context of the collection and that might not appear on their own in the corpus. \n",
    "\n",
    "Take for example the multi-term keywords _\"visual document analysis\"_ and _\"visual citation analysis\"_: Although at a high level these two concepts are clearly related (because they represent two specializations of visual analysis), making a more clear distinction between them might not be immediately obvious if they are found in a corpus related to visual analytics. In this case, the particles \"visual\" and \"analysis\" can be interpreted as noise because they do not add value to our understanding of the contents of the corpus. On the other hand, all three particles could carry important significance in other contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jp0CmAOpPALW"
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "  \n",
    "def stem_keywords(keywords):\n",
    "    terms_dict = {}\n",
    "    keywords_stemmed = []\n",
    "    stems_dictionary = {}\n",
    "    stems_dictionary_inv = {}\n",
    "\n",
    "    for doc in keywords:\n",
    "        doc_stemmed = []\n",
    "        for k in doc:\n",
    "            for tok in k.split():\n",
    "                if tok in stop_words:\n",
    "                    continue\n",
    "        \n",
    "                stem_tok = stemmer.stem(tok)\n",
    "\n",
    "                if stem_tok in stop_stems:\n",
    "                    continue\n",
    "                    \n",
    "                if stem_tok not in stems_dictionary:\n",
    "                    stems_dictionary[stem_tok] = [tok]\n",
    "                elif tok not in stems_dictionary[stem_tok]:\n",
    "                    stems_dictionary[stem_tok].append(tok)\n",
    "          \n",
    "                if k not in stems_dictionary_inv:\n",
    "                    stems_dictionary_inv[tok] = [stem_tok]\n",
    "                elif stem_tok not in stems_dictionary_inv[tok]:\n",
    "                    stems_dictionary_inv[tok].append(stem_tok)\n",
    "\n",
    "                doc_stemmed.append(stem_tok)\n",
    "        keywords_stemmed.append(remove_duplicates(doc_stemmed))\n",
    "\n",
    "    return(keywords_stemmed, stems_dictionary, stems_dictionary_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pVRcur6Qu_g"
   },
   "outputs": [],
   "source": [
    "def trace_stem(keyword_stem):\n",
    "    if keyword_stem in trace_stem.intersection_keywords_set:\n",
    "        return 'link'\n",
    "    elif keyword_stem in trace_stem.source_keywords_set:\n",
    "        return 'query'\n",
    "    elif keyword_stem in trace_stem.dest_keywords_set:\n",
    "        return 'target'\n",
    "    else:\n",
    "        raise RuntimeError('Error: keyword %s could not be traced' % keyword_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vR-Y60pIGX9K"
   },
   "outputs": [],
   "source": [
    "def trace_color(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "    trace = trace_stem(stemmer.stem(word))\n",
    "    if trace == 'query':\n",
    "        trace_color = '#d95f02'\n",
    "    elif trace == 'link':\n",
    "        trace_color = '#7570b3'\n",
    "    else:\n",
    "        trace_color = '#1b9e77'\n",
    "    return trace_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZY7KdbZtrO-"
   },
   "outputs": [],
   "source": [
    "stop_stems = ['visual', 'digit', 'human', 'humanit', 'humanist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Bq2kZOvEt8Is",
    "outputId": "8bfdb7a7-9068-4300-fe32-61e5034e4b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 257 source documents and 2123 destination documents\n",
      "Vocabulary size is 2720: 257 source stems, 320 intersection stems and 2143 destination stems\n"
     ]
    }
   ],
   "source": [
    "dh_papers_offset = len(dh_papers) - 1\n",
    "dh_keywords = [t['keywords'] for t in dh_papers]\n",
    "vis_keywords = [t['keywords'] for t in vis_papers]\n",
    "\n",
    "all_papers = dh_papers + vis_papers\n",
    "\n",
    "keywords = dh_keywords + vis_keywords\n",
    "keywords_flat = list(flatten(keywords))\n",
    "\n",
    "\n",
    "dh_docs_stemmed, dh_stems_dictionary, dh_stems_dictionary_inv = stem_keywords(dh_keywords)\n",
    "vis_docs_stemmed, vis_stems_dictionary, vis_stems_dictionary_inv = stem_keywords(vis_keywords)\n",
    "\n",
    "keywords_stemmed = dh_docs_stemmed + vis_docs_stemmed\n",
    "\n",
    "stems_dictionary = {}\n",
    "for key in (dh_stems_dictionary.keys() | vis_stems_dictionary.keys()):\n",
    "    if key in dh_stems_dictionary: stems_dictionary.setdefault(key, []).append(dh_stems_dictionary[key])\n",
    "    if key in vis_stems_dictionary: stems_dictionary.setdefault(key, []).append(vis_stems_dictionary[key])\n",
    "\n",
    "\n",
    "for k,v in stems_dictionary.copy().items():\n",
    "    stems_dictionary[k] = remove_duplicates(list(flatten(v)))\n",
    "  \n",
    "  \n",
    "stems_dictionary_inv = {**dh_stems_dictionary_inv, **vis_stems_dictionary_inv}\n",
    "\n",
    "\n",
    "\n",
    "source_keywords_set = remove_duplicates(list(flatten(dh_docs_stemmed)))\n",
    "dest_keywords_set = remove_duplicates(list(flatten(vis_docs_stemmed)))\n",
    "\n",
    "\n",
    "intersection_keywords_set = [k for k in source_keywords_set if k in dest_keywords_set]\n",
    "\n",
    "source_keywords_set = [k for k in source_keywords_set if k not in intersection_keywords_set]\n",
    "dest_keywords_set = [k for k in dest_keywords_set if k not in intersection_keywords_set]\n",
    "\n",
    "all_keywords_unique = source_keywords_set + intersection_keywords_set + dest_keywords_set\n",
    "\n",
    "trace_stem.source_keywords_set = source_keywords_set\n",
    "trace_stem.intersection_keywords_set = intersection_keywords_set\n",
    "trace_stem.dest_keywords_set = dest_keywords_set\n",
    "\n",
    "\n",
    "keyword2indx = {k:v for v,k in enumerate(all_keywords_unique)}\n",
    "indx2keyword = {indx:keyword for keyword,indx in keyword2indx.items()}\n",
    "\n",
    "\n",
    "print(\"There are %s source documents and %s destination documents\" % (len(dh_docs_stemmed), len(vis_docs_stemmed)))\n",
    "print('Vocabulary size is %s: %s source stems, %s intersection stems and %s destination stems' % \n",
    "  (len(all_keywords_unique), len(source_keywords_set), len(intersection_keywords_set), len(dest_keywords_set)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Occ60_LjfcfM"
   },
   "source": [
    "# Building counts\n",
    "\n",
    "Once keywords have been tokenized and stemmed, the next step of our method relies on counting the number of times each unique token appears on the two query and target BOWs. Similarly, we calculate skipgram counts in order to measure the number of times two tokens can be seen together. The skipgrams count is employed to construct a $N \\times N$ sparse matrix on which each cell represents the absolute count of observed associations between any two given tokens. At this stage, a binary term-document sparse matrix $T$ is also created. This binary matrix is employed in the last step of the method to project the results onto document space and produce a set of paper recommendations. \n",
    "\n",
    "With vocabulary $V_{t}$ we build a square term-context frequency matrix $F\\in\\mathcal{\\mathbb{R}}^{|V_{g}| \\times |V_{g}|} $ and a binary term-document matrix $B\\in\\mathcal{\\mathbb{B}}^{|V_{g}| \\times |C_{g}|}$. The word-context frequency matrix captures how many times two terms appear together in the corpus. Following <cite data-cite=\"5825190/WEDH9C6G\"></cite>, this translates into $\\#(w,c) \\cdot |C_{g}|$. \n",
    "\n",
    "Finally, we retain the provenance of each token by indexing the square matrix $\\mathbf{M}$ in the following manner:\n",
    "\n",
    "$\n",
    "  M_{i} =\n",
    "    \\begin{cases}\n",
    "      0 \\leq i < |V_{q}|  & \\iff M_{i} \\in V_{q} \\\\\n",
    "      |V_{q}| \\leq i < |V_{q}| + |V_{l}|  & \\iff M_{i} \\in V_{l} \\\\\n",
    "      |V_{q}| + |V_{l}| \\leq i < |V_{g}|  & \\iff M_{i} \\in V_{t}\n",
    "    \\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7GZLRSoPdEw"
   },
   "outputs": [],
   "source": [
    "def build_unigrams(keywords, verbose=False):\n",
    "    unigram_counts = Counter()\n",
    "  \n",
    "    for ii, doc in enumerate(keywords):\n",
    "        if ii % 2000 == 0 and verbose:\n",
    "            print(f'finished {ii/len(keywords):.2%} of papers')\n",
    "        for keyword in doc:\n",
    "            unigram_counts[keyword] += 1\n",
    "            \n",
    "    print('done')\n",
    "    print('vocabulary size: {}'.format(len(unigram_counts)))\n",
    "    print('most common: {}'.format(unigram_counts.most_common(10)))\n",
    "  \n",
    "    return unigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UODjk7FePBDA"
   },
   "outputs": [],
   "source": [
    "def build_skipgrams(keywords_stemmed, verbose=False):\n",
    "    n_docs = len(keywords_stemmed)\n",
    "    skipgram_counts = Counter()\n",
    "    for idoc, doc in enumerate(keywords_stemmed):\n",
    "        for keyword_a, keyword_b in itertools.combinations(doc, 2):\n",
    "            skipgram_a = (keyword_a, keyword_b)\n",
    "            skipgram_b = (keyword_b, keyword_a)\n",
    "            skipgram_counts[skipgram_a] += 1\n",
    "            skipgram_counts[skipgram_b] += 1\n",
    "        if idoc % 1000 == 0 and verbose:\n",
    "            print(f'finished {idoc/n_docs:.2%} of documents')\n",
    "\n",
    "    print('done')\n",
    "    print('number of skipgrams: {}'.format(len(skipgram_counts)))\n",
    "    print('most common: {}'.format(skipgram_counts.most_common(20)))\n",
    "\n",
    "    return skipgram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUn0x9En7VFA"
   },
   "outputs": [],
   "source": [
    "#Term-Document Matrix\n",
    "def build_td_mat(keywords, keyword2indx):\n",
    "    doc_indxs = []\n",
    "    keyword_indxs = []\n",
    "    tdat_values = []\n",
    "    for ii, doc in enumerate(keywords):\n",
    "        for keyword in doc:\n",
    "            doc_indxs.append(ii)\n",
    "            keyword_indxs.append(keyword2indx[keyword])\n",
    "            tdat_values.append(True)\n",
    "\n",
    "    return sps.csr_matrix((tdat_values, (doc_indxs, keyword_indxs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwPNOADYsyR9"
   },
   "outputs": [],
   "source": [
    "def build_wordcounts(skipgram_counts, keyword2indx, verbose=False):\n",
    "    row_indxs = []\n",
    "    col_indxs = []\n",
    "    dat_values = []\n",
    "    ii = 0\n",
    "    for (keyword1, keyword2), sg_count in skipgram_counts.items():\n",
    "        ii += 1\n",
    "        if ii % 1000 == 0 and verbose:\n",
    "            print(f'finished {ii/len(skipgram_counts):.2%} of skipgrams')\n",
    "        key1_indx = keyword2indx[keyword1]\n",
    "        key2_indx = keyword2indx[keyword2]\n",
    "        \n",
    "        row_indxs.append(key1_indx)\n",
    "        col_indxs.append(key2_indx)\n",
    "        dat_values.append(sg_count)\n",
    "    \n",
    "    wwcnt_mat = sps.csr_matrix((dat_values, (row_indxs, col_indxs)))\n",
    "    print('wwcnt sparse matrix was built (%d, %d)' % wwcnt_mat.shape)\n",
    "    return wwcnt_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "vocabulary size: 2720\n",
      "most common: [('data', 492), ('analysi', 316), ('interact', 299), ('volum', 285), ('render', 269), ('inform', 259), ('analyt', 237), ('model', 190), ('design', 170), ('graph', 145)]\n",
      "done\n",
      "number of skipgrams: 84158\n",
      "most common: [(('volum', 'render'), 207), (('render', 'volum'), 207), (('data', 'analysi'), 104), (('analysi', 'data'), 104), (('interact', 'data'), 60), (('data', 'interact'), 60), (('field', 'vector'), 55), (('vector', 'field'), 55), (('data', 'analyt'), 52), (('analyt', 'data'), 52), (('analyt', 'analysi'), 52), (('analysi', 'analyt'), 52), (('interact', 'analyt'), 51), (('analyt', 'interact'), 51), (('analysi', 'interact'), 48), (('interact', 'analysi'), 48), (('design', 'studi'), 48), (('studi', 'design'), 48), (('interact', 'inform'), 47), (('inform', 'interact'), 47)]\n",
      "wwcnt sparse matrix was built (2720, 2720)\n"
     ]
    }
   ],
   "source": [
    "unigram_counts = build_unigrams(keywords_stemmed)\n",
    "tf_bin_mat = build_td_mat(keywords_stemmed, keyword2indx)\n",
    "tf_bin_list = tf_bin_mat.toarray().tolist()\n",
    "\n",
    "skipgram_counts = build_skipgrams(keywords_stemmed)\n",
    "wwcnt_mat = build_wordcounts(skipgram_counts, keyword2indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis\n",
    "We selected Latent Semantic Analysis (LSA), a distributional semantic model (DSM) to define a semantic space of keywords.\n",
    "\n",
    "LSA is a theory of language and distributional semantic model that extracts and represents the contextual-usage meaning of \n",
    "words by applying statistical calculations to a corpus of text <cite data-cite=\"5825190/B4LPB8XA\"></cite>. LSA (or LSI, for Latent Semantic Indexing, as it is known \n",
    "in the information retrieval community) assumes that the occurring patterns of words in a variety of contexts are able \n",
    "to determine the degree of similarity among such words <cite data-cite=\"5825190/YJCC8EDY\"></cite>. \n",
    "\n",
    "LSA is a fully unsupervised method that, unlike the case of predictive semantic models, does not employ any knowledge base \n",
    "or human-generated dictionary. Rather, it relies solely on the analysis of raw text. Because LSA originated in the psychology community, \n",
    "since its beginnings it was thoroughly evaluated to measure its accuracy in replicating human judgments of meaning similarity <cite data-cite=\"5825190/U2RP32HP\"></cite>. The \n",
    "similarity estimates derived by LSA are not based on simple contiguity frequencies or co-occurrence, but rather they depend on a \n",
    "deeper statistical analysis that extracts the underlying semantics from a corpus. \n",
    "\n",
    "This kind of analysis has the positive effect of producing results that are conceptually similar in meaning to a given query term even if these results do not share specific words with the search criteria. Beyond that, some authors have stressed the role of LSA as a fundamental computational theory of the acquisition and representation of knowledge that is closely related to the inductive property of learning, for which people seem to acquire much more knowledge than appears to be available in experience <cite data-cite=\"5825190/SD9XSNXL\"></cite>.\n",
    "\n",
    "## Singular Value Decomposition\n",
    "To produce a semantic analysis of the words in a corpus, LSA makes use of a well-known linear algebra matrix decomposition method called Singular Value Decomposition (SVD) that we briefly summarize for the reader hereafter: \n",
    "\n",
    "SVD is used to decompose a given matrix $M$ into the product of three matrices $U \\Sigma V^{T}$, where $U$ and $V$ are orthonormal \n",
    "($U^{T} U = V^{T} V = I$) and $\\Sigma$ is a diagonal matrix of sorted singular values of the same rank r as the input matrix. \n",
    "\n",
    "Let $\\Sigma_{k}$, where $k < r$, the diagonal formed by the k first singular values of $\\Sigma$ and let $U_{k}$ and $V_{k}$ be the matrices that result from keeping only the first \\textit{k} columns in $U$ and $V$. The matrix $\\hat{M} = U_{k} \\Sigma_{k} V^T_{k}$ is the rank k matrix that minimizes the Frobenius norm between the input matrix $M$ and any other rank-k matrix, i.e. $\\hat{M} \\in {arg\\,min} \\Vert M - \\hat{M}\\Vert_{F}$. This is, the resulting matrix is the best k-dimensional approximation to the original in the least-squares sense (minimizing covariance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "haN4nxpHwzPY"
   },
   "outputs": [],
   "source": [
    "def svd_reduce(pmi_use, embedding_size):\n",
    "    print('Will reduce matrix of shape (%d, %d) with embedding_size=%d' %(pmi_use.shape[0], pmi_use.shape[1], embedding_size))\n",
    "    return sps.linalg.svds(pmi_use, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pN1rj0YTAOAx"
   },
   "outputs": [],
   "source": [
    "def generate_wordvecs(uu):\n",
    "    word_vecs = uu\n",
    "    word_vecs_norm = normalize(uu, norm='l2')\n",
    "    return (word_vecs, word_vecs_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Mutual Infomration\n",
    "\n",
    "In previous sections, we explained that LSA extracts latent semantics from factorizing a co-occurrence statistics matrix $\\mathbf{M}$. This matrix can be built via different methods, such as term-frequency (TF) or term frequency - inverse document frequency (TF-IDF). In our case, we detected that narrow-domain corpora produce a great overlapping of insignificant words (noise) that we wanted to eliminate. To this end, we relied on a well-known metric of information science, Pointwise Mutual Information (PMI) <cite data-cite=\"5825190/GEINZ3ZS\"></cite> because 1. provides an efficient manner to remove repetitive terms from the analysis and 2. when used in conjunction with LSA/SVD is capable of generating linguistic models that excel at distributional similarity tasks <cite data-cite=\"5825190/AGWC3HVT\"></cite>. \n",
    "\n",
    "The usage of the smoothed PPMI matrix in LSA favors the detection of infrequent and informative relationships occurring in the high-dimensional semantic space over uninformative terms. This feature helps to provide a view of the target corpus that is based on the specifics of the user-generated query corpus and to identify keyword pairs that share a common latent meaning.\n",
    "\n",
    "PMI encodes the probability for a pair of tokens to be seen together in a document with respect to the probability of seeing those two same tokens in the whole corpus. This probability is defined as the log ratio between \\textit{w} and \\textit{c}'s joint probability and the product of their marginal probabilities. These probabilities can be extracted empirically from the corpus by counting the number of times \\textit{w} and \\textit{c} appear in the same document divided by the times they can be seen in other documents. In this paper, we do not consider the order in which terms appear within a document and therefore, the word-context matrix is built solely on co-occurrence. \n",
    "\n",
    "Similarly, the term-document matrix is a sparse binary matrix whose entries are defined as $B(t,d) = \\{1 \\text{ if t occurs in d or 0 otherwise}\\}$.\n",
    "\n",
    "\n",
    "(1) $PMI(w,c) = \\log\\frac{\\hat{P}(w,c)}{\\hat{P}(w)\\hat{P}(c)} = \\log\\frac{\\#(w,c) \\cdot |C_{T}|}{\\#(w) \\cdot \\#(c)}$\n",
    "\n",
    "Following recommendations in the recent NLP literature \\cite{levy_improving_2015}, we employ an smoothed version of the PMI matrix. During our experiments, we found that setting the smoothing factor $\\alpha$ to 0.95 yielded the best results in the similarity task, which is in line with observations from other studies: \n",
    "\n",
    "(2) $SPMI(w,c) = \\log\\frac{\\hat{P}(w,c)}{\\hat{P}(w)\\hat{P}_{\\alpha}(c)}$\n",
    "\n",
    "where the smoothed unigram distribution of the context is:\n",
    "\n",
    "(3) $\\hat{P}_{\\alpha}(c) = \\frac{\\#(c)^{\\alpha}}{\\sum_{c}{\\#(c)^{\\alpha}}}$\n",
    "\n",
    "The pairwise results are stored in a Smoothed PMI matrix $M^{SPMI}$ that matches the original dimensions of $F$, $|V_{T}| \\times |V_{T}|$. A common problem with $M^{SPMI}$ is that it contains entries of the form $\\text{PMI}(w,c) = \\log 0 = -\\infty$ for word-context pairs that were never observed. This issue is solved in the NLP literature by using \\textit{positive} PMI (PPMI), in which the negative entries are replaced by 0:\n",
    "\n",
    "\n",
    "(4) $M = SPPMI(w,c)=\n",
    "    \\begin{cases}\n",
    "      SPMI(w,c) & \\text{if}\\ SPMI(w,c)>0 \\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\label{eq:sppmi}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PY41n9jUutXt"
   },
   "outputs": [],
   "source": [
    "def build_pmis(wwcnt_mat, skipgram_counts, keyword2indx, verbose=False):\n",
    "    num_skipgrams = wwcnt_mat.sum()\n",
    "    assert(sum(skipgram_counts.values())==num_skipgrams)\n",
    "\n",
    "    # for creating sparse matrix\n",
    "    row_indxs = []\n",
    "    col_indxs = []\n",
    "    sppmi_values = []\n",
    "\n",
    "    # smoothing\n",
    "    alpha = 0.95\n",
    "    nca_denom = np.sum(np.array(wwcnt_mat.sum(axis=0)).flatten()**alpha)\n",
    "    sum_over_words = np.array(wwcnt_mat.sum(axis=0)).flatten()\n",
    "    sum_over_words_alpha = sum_over_words**alpha\n",
    "    sum_over_contexts = np.array(wwcnt_mat.sum(axis=1)).flatten()\n",
    "\n",
    "    ii = 0\n",
    "    for (keyword1, keyword2), sg_count in skipgram_counts.items():\n",
    "        ii += 1\n",
    "        if ii % 5000 == 0 and verbose:\n",
    "          print(f'finished {ii/len(skipgram_counts):.2%} of skipgrams')\n",
    "\n",
    "        keyword1_indx = keyword2indx[keyword1]\n",
    "        keyword2_indx = keyword2indx[keyword2]\n",
    "\n",
    "        nwc = sg_count\n",
    "        Pwc = nwc / num_skipgrams\n",
    "        nw = sum_over_contexts[keyword1_indx]\n",
    "        Pw = nw / num_skipgrams\n",
    "\n",
    "        nc = sum_over_words[keyword2_indx]\n",
    "        Pc = nc / num_skipgrams\n",
    "\n",
    "        nca = sum_over_words_alpha[keyword2_indx]\n",
    "        Pca = nca / nca_denom\n",
    "\n",
    "        sppmi = max(np.log2(Pwc/(Pw*Pca)), 0)\n",
    "\n",
    "        row_indxs.append(keyword1_indx)\n",
    "        col_indxs.append(keyword2_indx)\n",
    "        sppmi_values.append(sppmi)\n",
    "    \n",
    "    \n",
    "    sppmi_mat = sps.csr_matrix((sppmi_values, (row_indxs, col_indxs)))\n",
    "  \n",
    "    print('sparse ppmi matrix was built')\n",
    "\n",
    "    return sppmi_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "RtqGCyPpiiLg",
    "outputId": "28b7ae90-83f5-4e15-c94f-15b5989a7346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse ppmi matrix was built\n",
      "Will reduce matrix of shape (2720, 2720) with embedding_size=50\n"
     ]
    }
   ],
   "source": [
    "#Build ppmi \n",
    "sppmi_mat = build_pmis(wwcnt_mat, skipgram_counts, keyword2indx)\n",
    "\n",
    "uu, ss, vv = svd_reduce(sppmi_mat, 50)\n",
    "word_vecs, word_vecs_norm = generate_wordvecs(uu)\n",
    "\n",
    "#use normalized/not normalized\n",
    "use_vecs = word_vecs_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnsjdJD1l3b2"
   },
   "source": [
    "## Distance Matrix\n",
    "\n",
    "One of the most popular (dis)similarity measures employed in NLP is the cosine of the angle formed by two word vectors <cite data-cite=\"5825190/SAAU4NU2\"></cite>. This measure discards the length of the vectors and quantifies the difference in their direction in multidimensional space. We selected this similarity measure because, as reported by other studies, it is adequate to represent cognitive similarity beyond simple linguistic similarity <cite data-cite=\"undefined\"></cite>. The formula of the cosine is well known and can be applied easily to the LSA vectors to build a distance matrix $D$:\n",
    "\n",
    "(5) $\n",
    "    D(x,y) = cos(x,y) = \\frac{\\sum^{n}_{i=1} x_{i} \\cdot y_{i}}{\\sqrt{\\sum^{n}_{i=1} x^{2}_{i} \\cdot \\sum^{n}_{i=1} y^{2}_{i}}}\n",
    "$\n",
    "\n",
    "Analogously, the similarity between two vectors can be expressed as:\n",
    "\n",
    "(6) $\n",
    "    S(x,y) = 1 - D(x,y)\n",
    "$\n",
    "\n",
    "As a final step, we employed the similarity matrix $S$ to detect and merge synonyms (i.e. token pairs with $S(x,y) \\approx 0$), which resulted in a reduction in vocabularies sizes ($|V_{q}| = 176, |V_{t}| = 1745, |V_{l}| = 320$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "mdnD3jNbl4b0",
    "outputId": "206e5a73-3344-43cc-80e9-e5414cd651ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding synonyms...\n",
      "Found 479 synonyms. Operating with 2241 vectors now\n"
     ]
    }
   ],
   "source": [
    "#Generate distance matrix\n",
    "Y = pdist(use_vecs, 'cosine')\n",
    "\n",
    "\n",
    "print('Finding synonyms...')\n",
    "distance_matrix = squareform(Y)\n",
    "dist_matrix_sq = np.triu(distance_matrix)\n",
    "syns = {}\n",
    "remove = []\n",
    "rows = dist_matrix_sq.shape[0]\n",
    "cols = dist_matrix_sq.shape[0]\n",
    "for x in range(0, rows):\n",
    "    for y in range(0, cols):\n",
    "        if x >= y:\n",
    "            continue\n",
    "        elif dist_matrix_sq[x][y] <= 0.01:\n",
    "            if x in syns:\n",
    "                syns[x].append(y)\n",
    "            else:\n",
    "                syns[x] = [y]\n",
    "            if y in syns:\n",
    "                syns[y].append(x)\n",
    "            else:\n",
    "                syns[y] = [x]\n",
    "            remove.append(y)\n",
    "\n",
    "keep = []\n",
    "for i in range(0, rows):\n",
    "    if i not in remove:\n",
    "        keep.append(i)\n",
    "\n",
    "use_vecs_c = use_vecs[keep]\n",
    "\n",
    "sppmi_mat_c = sppmi_mat[keep,:]\n",
    "sppmi_mat_c = sppmi_mat_c[:,keep]\n",
    "\n",
    "print('Found %s synonyms. Operating with %s vectors now' % (len(set(remove)), len(use_vecs_c)))\n",
    "\n",
    "Y_c = pdist(use_vecs_c, 'cosine')\n",
    "\n",
    "\n",
    "sep_indx_src = len(source_keywords_set) -1\n",
    "sep_indx_inter = len(source_keywords_set) + len(intersection_keywords_set) - 1\n",
    "\n",
    "new_seps = []\n",
    "\n",
    "prev = 'query'\n",
    "for i in range(len(use_vecs_c)):\n",
    "    current = trace_stem(indx2keyword[keep[i]])\n",
    "    if current != prev:\n",
    "        new_seps.append(i)\n",
    "    prev = current\n",
    "    \n",
    "\n",
    "sep_indx_src_c = new_seps[0] - 1\n",
    "sep_indx_inter_c = new_seps[1] - 1\n",
    "indx2keyword_c = {k:indx2keyword[keep[k]] for k in range(len(use_vecs_c))}\n",
    "keyword2indx_c = {v:k for k,v in indx2keyword_c.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oAMeNWWo3FZJ",
    "outputId": "9da2358c-6b4f-43f6-ffd6-23a5fea4e904"
   },
   "outputs": [],
   "source": [
    "syn_query = []\n",
    "syn_link = []\n",
    "syn_target = []\n",
    "\n",
    "for k,v in indx2keyword_c.items():\n",
    "    trace = trace_stem(v)\n",
    "    if trace == 'query':\n",
    "        syn_query.append(v)\n",
    "    elif trace == 'link':\n",
    "        syn_link.append(v)\n",
    "    else:\n",
    "        syn_target.append(v)\n",
    "\n",
    "# print(len(syn_query), len(syn_link), len(syn_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRVNLRMomU64"
   },
   "source": [
    "## Analyzing Inter-group Similarities\n",
    "\n",
    "The second stage of our method focuses on exploring the similarity matrix $S$ that was obtained in the last step. To overcome the conceptual distance between the query and target corpora, we look for structural patterns in the similarity relationships between keywords on the query vocabulary and those found exclusively in the target vocabulary. For this task, we rely on the construction of a complete graph $G$ using the distance matrix $D$, which enables us to analyze the similarity between nodes (tokens) using different scaling techniques to reduce the complexity of the resulting graph. \n",
    "\n",
    "\n",
    "In order to map all tokens in $V_{t}$ to their counterpart in $V_q$, we identify the shortest path that connects a token in $V_{t}$ to any other token $V_{q}$. Formally, we can define the set of shortest paths $P'_{j}$ from the token $j$ in $V_{t}$ to all tokens in $V_{q}$ as the sequence of node pairs $(t_{j}^{t},t_{k1}^{r}), (t_{k1}^{r},t_{k2}^{r}), \\dots, (t_{kl}^{r},t_{i}^{q})$ with $r \\in \\{q,l,t\\}$. Given that all pairs are edges representing distances, the sum of all distance pairs in a path in $P'$ gives the total distance between the token $t_{j}^{t}$ and every other token in $V_{q}$. Therefore, there exists a shortest path $P$ in $P'$ connecting the node $t_{j}^{t}$ to another node $t_{i}^{q}$ that, by (6), yields a maximum similarity over all other alternative paths to tokens in $V_{q}$. Note that when $|P| = 1$, the similarity score $sim$ is equal to the value of the similarity matrix $S$ at $S(t_{j}, t_{i})$.\n",
    "\n",
    "(7) $\n",
    "    sim(t_{j}^{t}, t_{i}^{q}) = 1 - \\min_{P \\in P'_{j}}\\{\\sum_{k=1}^{l}{dist(t_{k},t_{k+1})} \\mid (t_{k},t_{k+1}) \\in P\\}\\\\\n",
    "$\n",
    "\n",
    "\n",
    "By (7), the path $P_{t^{t}_{j}}$ that maximizes the similarity score $sim$ is a \\textit{significant} path of the target token $t^{t}_{j}$ in $G$ because it connects it to its most similar counterpart in $V_{q}$. These paths can be easily computed by a multi-source version of the Dijkstra algorithm.\n",
    "\n",
    "After all shortest paths have been calculated, we can group similar nodes by the number of shared links by their respective paths from $V_{t}$ to $V_{q}$. In this way, sets of target nodes that present structural similarities in their relationship with the query dataset can be grouped together. This builds upon the idea that nodes related to the same topics have the likelihood to share more links in the shortest paths that relate them to tokens in $V_{q}$, while shortest paths of dissimilar nodes have few or no links in common <cite data-cite=\"5825190/2M3GJCKB\"></cite>.\n",
    "\n",
    "\n",
    "Particularly, the subgraph resulting from merging two or more shortest paths with common elements $P_{1}, P_{2} \\dots P_{n}$ is a spanning tree of its nodes in $G$. This procedure is illustrated in the figure below. On the left, two shortest paths for tokens $t_{1}^{t}$ and $t_{2}^{t}$ are shown. As $|V_{t}| \\gg |V_{q}|$, some paths will share at least a common destination token in $V_{q}$, $t_{1}^{q}$ in the example. Input paths are ultimately merged into the same tree $T_{t_{1}^{q}}$.\n",
    "\n",
    "<img src='img/path-generation.png'>*Figure*: Shortest paths $P(t^{1}_{t})$ (left, top) and $P(t^{2}_{t})$ (left, bottom) connecting tokens $t^{1}_{t}$ and $t^{2}_{t}$ to their closest neighbor in $V_{q}$. The proposed method detects coincident tokens in the resulting paths and constructs the spanning tree that contains them. This results in a partition of the dataset in which tokens in $V_{t}$ are grouped together if they relate to $V_{q}$ in a similar manner.</img>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After merging paths with common elements we obtain a set of trees $T = \\{T_{1}, T_{2}\\dots T_{i}\\}$ for each token $t^{q}_{i} \\in V_{q}$ present in any path in $P$. Note that at this point not all tokens in $V_{q}$ can be found in $T$, whereas all tokens in $V_{t}$ are. The solution to this issue is trivial and can be solved by adding a token $t^{j}_{q}$ not present in $T$ to the MST of its nearest-neighbor given that there are not any other shorter paths connecting $t^{j}_{q}$ to any other token in $V_{t}$. At the end of this process, any tree, or a combination of trees in $T$, along with related documents, can be represented in a visualization according to the procedure outlined in the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGLD1r3tpT3Y"
   },
   "source": [
    "### Generating the model\n",
    "The following cells generate a visualization model based on paths extracted from proximity data. \n",
    "If you want to recreate the process (*it could take several hours*),\n",
    "remove the pre-generated pickle file './model/all-paths.pkl' and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JVQBk9jnLa0"
   },
   "outputs": [],
   "source": [
    "def generate_paths(dist_matrix, sep_indx_src, sep_indx_inter, indx2keyword):\n",
    "    dist_matrix_sq = np.triu(squareform(dist_matrix))\n",
    "    dists_graph = nx.from_numpy_matrix(dist_matrix_sq)\n",
    "  \n",
    "    paths_by_dest = {}\n",
    "    paths_location = './model/all-paths.pkl'\n",
    "  \n",
    "    try:\n",
    "        infile = open(paths_location, 'rb')\n",
    "        paths_by_dest = pickle.load(infile)\n",
    "    except FileNotFoundError:      \n",
    "        for j in range(sep_indx_inter + 1, len(indx2keyword)):\n",
    "            print('Calculating best path for %s/%s' % (j, len(indx2keyword) - 1))\n",
    "            dist, path = nx.multi_source_dijkstra(dists_graph, set(range(0,sep_indx_src + 1)), target=j)\n",
    "            paths_by_dest[j] = {'path' : path, 'distance': dist}\n",
    "            print(indx2keyword[j], paths_by_dest[j]['distance'], [(indx2keyword[n], trace_stem(indx2keyword[n])) for n in paths_by_dest[j]['path']])\n",
    "    \n",
    "    output = open('all-paths.pkl', 'wb')\n",
    "    pickle.dump(paths_by_dest, output)\n",
    "    \n",
    "    shutil.move('all-paths.pkl', paths_location)\n",
    "\n",
    "  \n",
    "    return dists_graph, paths_by_dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fsXj5lxlpKHM"
   },
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HxZ4dPZmXhp"
   },
   "outputs": [],
   "source": [
    "def sortFn(a):\n",
    "    cmp_str = ''\n",
    "    for i in range(len(a)):\n",
    "        cmp_str += indx2keyword_c[a[i]]\n",
    "\n",
    "    return cmp_str\n",
    "\n",
    "def merge_subs(lst_of_lsts):\n",
    "    copy_list = copy.deepcopy(lst_of_lsts)\n",
    "    res = []\n",
    "    for row in copy_list:\n",
    "        for i, resrow in enumerate(res):\n",
    "            if row[0]==resrow[0]:\n",
    "                res[i] += row[1:]\n",
    "                break\n",
    "        else:\n",
    "            res.append(row)\n",
    "    return res\n",
    "\n",
    "dists_graph, paths_by_dest = generate_paths(Y_c, sep_indx_src_c, sep_indx_inter_c, indx2keyword_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2452
    },
    "colab_type": "code",
    "id": "KRv8gD-QNXDh",
    "outputId": "34f22eea-14a1-440a-8d00-619ee50a06a7"
   },
   "outputs": [],
   "source": [
    "all_paths = [v['path'] for k,v in paths_by_dest.items()]\n",
    "\n",
    "merged_paths_sorted = sorted(merge_subs(all_paths), key=sortFn)\n",
    "\n",
    "# for p in merged_paths_sorted:\n",
    "#     print([(indx2keyword_c[j], trace_stem(indx2keyword_c[j])) for j in (p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2452
    },
    "colab_type": "code",
    "id": "0b3Zb7S1u6-E",
    "outputId": "cae17680-022c-42c9-b7c6-310d4335cbe7"
   },
   "outputs": [],
   "source": [
    "merged_paths_dict = {}\n",
    "for p in merged_paths_sorted:\n",
    "    merged_paths_dict[indx2keyword_c[p[0]]] = p\n",
    "#     print([('/'.join(stems_dictionary[indx2keyword_c[j]]), trace_stem(indx2keyword_c[j])) for j in sorted(p)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9oLmaFVK42m"
   },
   "source": [
    "# Visualizing documents via keyword proximity\n",
    "\n",
    "In the last stage, the user is expected to provide a set of keywords to explore the collection. Following the reasoning explained in previous sections, the user employs keywords specific to the query vocabulary to obtain affine keywords and documents from the target corpus. These elements are presented to the user in a visualization that shows exploration paths related to the input query expression. The user is then able to progressively form a mental image of the target corpus by following these paths and, optionally, perform further research on the list of document suggestions that are displayed in the same visualization space. In this section, we comment on the necessary steps that were taken to produce this expected output. \n",
    "\n",
    "The visualization employs a single tree as input, which can be one of the trees in $T$ if only a single keyword is provided, or a tree resulting from combining two or more trees in $T$. The tree is drawn in the plane using the Kamada-Kawai layout algorithm <cite data-cite=\"5825190/3CIKKD6P\"></cite>, where tokens are depicted as vertices (text) and cosine distances as edges (solid lines) in the network. Query, link and target keywords are shown in orange, blue and green colors, respectively. Tokens are translated into their original forms to ensure the readability of the results. In a subsequent step, the visualization is completed by representing documents into the semantic subspace defined by $T$. Firstly, the $TD$ matrix is filtered to obtain documents that contain any of the terms in $T$. Note that each of the resulting documents may contain one or more terms (components) of the semantic subspace $T$. Then, documents are projected according to their components' positions in the plane, as assigned by the Kamada-Kawai layout.\n",
    "\n",
    "<img src='img/doc-projections.png'>*Figure*: Documents are projected into the 2D representation of the semantic subspace defined by $T$. $d_{1}$ is projected to its only component in the subspace, $t_{1}$. Similarly, $d_{2}$ contains terms $t_{3}$ and $t_{4}$ of and therefore it is projected at the mid-distance of the link betwen the two terms. Finally, documents such as $d_{3}$ that contain three or more terms are projected at the centroid of the convex hull formed by the positions of such terms in the plane.</img>\n",
    "\n",
    "Documents are represented as dots in the visualization and follow the same color scheme as keywords: Documents on the query corpus are shown in orange, whereas those appearing in the target dataset are shown in green. Whenever two or more documents share the same position in the plane, they are aggregated in a visual encoding (the size of the circle). We represent links between a document and their related components in the plane with a dashed line, which facilitates the task of identifying relationships between terms and documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDQqYh8IdSUC"
   },
   "outputs": [],
   "source": [
    "def get_recommendations_for_path(component):\n",
    "    nodes = list(component.nodes())\n",
    "    token_indices = [keep[n] for n in nodes]\n",
    "    docs = []\n",
    "    for doc_index, doc in enumerate(tf_bin_list):\n",
    "        doc_dict = {}\n",
    "        doc_tokens = []\n",
    "        for token_index, token in enumerate(doc):\n",
    "            if token == True and token_index in token_indices:\n",
    "                doc_tokens.append(token_index)\n",
    "        if len(doc_tokens) > 0:\n",
    "            the_doc = all_papers[doc_index]\n",
    "            doc_dict['title'] = the_doc['title']\n",
    "            doc_dict['keywords'] = the_doc['keywords']\n",
    "            doc_dict['title'] = the_doc['title']\n",
    "\n",
    "            if doc_index <= dh_papers_offset:\n",
    "                doc_dict['trace'] = 'query'\n",
    "            else:\n",
    "                doc_dict['trace'] = 'target'\n",
    "\n",
    "            doc_dict['tokens'] = [indx2keyword[i] for i in doc_tokens]\n",
    "            doc_dict['token_indices'] = doc_tokens\n",
    "            doc_dict['token_indices_c'] = [nodes[token_indices.index(i)] for i in doc_tokens]\n",
    "            docs.append(doc_dict)\n",
    "        \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wh-jggChpuq4"
   },
   "outputs": [],
   "source": [
    "def scale_number(unscaled, to_min, to_max, from_min, from_max):\n",
    "    if from_min == from_max: return to_max\n",
    "    return (to_max-to_min)*(unscaled-from_min)/(from_max-from_min)+to_min\n",
    "\n",
    "def build_keywords_tree(G, indx2keyword, stems_dictionary):\n",
    "    counts = []\n",
    "    counts.extend(list(map(lambda x: x[1][\"count\"], list(G.nodes(data=True)))))\n",
    "  \n",
    "    nodes = G.nodes()\n",
    "  \n",
    "    min_dist = 0\n",
    "    max_dist = 0\n",
    "  \n",
    "    for row, data in nx.shortest_path_length(G, weight='weight'):\n",
    "        for col, dist in data.items():\n",
    "            if min_dist > dist:\n",
    "                min_dist = dist\n",
    "            if max_dist < dist:\n",
    "                max_dist = dist\n",
    "  \n",
    "    df = pd.DataFrame(index=nodes, columns=nodes)\n",
    "    for row, data in nx.shortest_path_length(G, weight='weight'):\n",
    "        for col, dist in data.items():\n",
    "            scaled_dist = scale_number(dist, 1, 4, min_dist, max_dist)\n",
    "            df.loc[row,col] = scaled_dist\n",
    "  \n",
    "    df = df.fillna(df.max().max())\n",
    "\n",
    "    pos = nx.kamada_kawai_layout(G, scale=1.0, dim=2, weight='weight', dist=df.to_dict())\n",
    "  \n",
    "  \n",
    "    x = {k:float('%.4f' % v[0])  for k,v in pos.items()}\n",
    "    y = {k:float('%.4f' % v[1]) for k,v in pos.items()}\n",
    "  \n",
    "    nx.set_node_attributes(G, x, 'x')\n",
    "    nx.set_node_attributes(G, y, 'y')\n",
    "  \n",
    "    graph_json = json_graph.node_link_data(G)\n",
    "\n",
    "    docs = get_recommendations_for_path(G)\n",
    "    node_list = list(nodes)\n",
    "\n",
    "    docs_json = {}\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_keyword_ids = \"+\".join([str(k) for k in sorted(doc['token_indices_c'])])\n",
    "        if doc_keyword_ids in docs_json:\n",
    "            #Doc already added\n",
    "            docs_json[doc_keyword_ids]['count'] += 1\n",
    "            docs_json[doc_keyword_ids]['docs'].append(doc)\n",
    "        else:\n",
    "            if len(doc['token_indices_c']) == 1:\n",
    "                cx = pos[doc['token_indices_c'][0]][0]\n",
    "                cy = pos[doc['token_indices_c'][0]][1]\n",
    "            elif len(doc['token_indices_c']) == 2:\n",
    "                ax = pos[doc['token_indices_c'][0]][0]\n",
    "                ay = pos[doc['token_indices_c'][0]][1]\n",
    "                bx = pos[doc['token_indices_c'][1]][0]\n",
    "                by = pos[doc['token_indices_c'][1]][1]\n",
    "                cx = (ax + bx) / 2\n",
    "                cy = (ay + by) / 2\n",
    "            else:\n",
    "                the_points = [ (pos[i][0], pos[i][1]) for i in doc['token_indices_c']]\n",
    "                hull = ConvexHull(the_points)\n",
    "                cx = np.mean(hull.points[hull.vertices,0])\n",
    "                cy = np.mean(hull.points[hull.vertices,1])\n",
    "\n",
    "            docs_json[doc_keyword_ids] = {\n",
    "              'cx': cx,\n",
    "              'cy': cy,\n",
    "              'count': 1,\n",
    "              'docs': [doc]\n",
    "            }\n",
    "    \n",
    "  \n",
    "    json_obj = {'graph' : graph_json, 'docs' : docs_json}\n",
    "\n",
    "    return json.dumps(json_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Significant Paths\n",
    "\n",
    "Apart from the visualization of a single tree, our visualization scheme also supports the combination of two or more query terms to represent related keywords and documents. Given that by definition all trees in $T$ are disjoint subgraphs of $G$, we can find an MST in $G$ that contains all vertices in $T_{1}, T_{2}, \\dots T_{n}$ and that presents the minimum edit distance of all possible MSTs to the sum of all subgraphs. This reasoning is depicted in the Figure below. \n",
    "\n",
    "<img src='img/path-query.png'>*Figure*: Paths for the user-provided terms $T_{t_{1}^{q}}$ and  $T_{t_{2}^{q}}$ are combined into a new path that results from calculating the MST of nodes in the two paths. This procedure ensures that the two paths are presented in the most coherent possible way in the visualization.</img>\n",
    "\n",
    "The tree resulting from the combination of the two paths has similar properties to any other tree in $T$ and thus can be displayed in the same manner as we describe in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['aborigin', 'academ', 'ancient', 'app', 'arab', 'armenian', 'audio', 'audiovisu', 'augustan-era', 'australian', 'barcod', 'bayerisch', 'betham', 'bibliographi', 'biographi', 'black', 'charact', 'co-retweet', 'cohes', 'collat', 'coloc', 'confer', 'conserv', 'cooccurr', 'coword', 'crossinstitut', 'diachron', 'diplomat', 'disaggreg', 'drama', 'dramat', 'dunhuang', 'editor', 'eigenpag', 'encyclopedia', 'entiti', 'epigraphi', 'epub', 'fabric', 'face', 'femin', 'feminist', 'fennica', 'floor', 'french', 'full', 'galeazza', 'genesi', 'geo-annot', 'geo', 'gephi', 'german', 'good', 'gothic', 'hansard', 'historiographi', 'htrc', 'humain', 'hypergraph', 'id', 'implic', 'inclus', 'institut', 'interdisciplinar', 'intermedia', 'intertextu', 'island', 'itinerari', 'jazz', 'justic', 'laboring-class', 'latin', 'lexic', 'loc', 'madrid', 'manuscript', 'mediev', 'mesoamerica', 'ming', 'miss', 'monasteri', 'morphosyntact', 'multilay', 'multilingu', 'museographi', 'narratolog', 'new', 'nobil', 'novel', 'novelti', 'ocr', 'pars', 'pedagogi', 'polit', 'popular', 'practice-bas', 'propoerti', 'prosopographi', 'protect', 'queer', 'racial', 'religion', 'renaiss', 'reproduct', 'reus', 'rhyme', 'r', 'road', 'roll', 'russian', 'scientometr', 'semi-automat', 'shakespear', 'slave', 'sociolinguist', 'sociolog', 'spam', 'stain', 'stemmatolog', 'surrog', 'syntax', 't-sne', 'tei', 'temporospati', 'tesseract', 'testament', 'text-imag', 'three-dimension', 'tolstoy', 'tortur', 'transmedia', 'txm', 'ukiyo-', 'uniti', 'user-test', 'willa', 'women', 'zipf'])\n"
     ]
    }
   ],
   "source": [
    "#Use these keywords to produce queries \n",
    "print(merged_paths_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dR9zAKwwtEp9"
   },
   "outputs": [],
   "source": [
    "# path_keys = ['co-retweet', 'cooccurr']\n",
    "\n",
    "# path_keys = ['bayerisch', 'jazz']\n",
    "\n",
    "# path_keys = ['aborigin']\n",
    "\n",
    "# path_keys = ['palaeographi', 'mediev']\n",
    "\n",
    "# path_keys = ['russian', 'transmedia']\n",
    "\n",
    "# path_keys = ['women']\n",
    "\n",
    "# path_keys = ['co-retweet', 'coword']\n",
    "\n",
    "# path_keys = ['coword']\n",
    "\n",
    "path_keys = ['shakespear']\n",
    "# path_keys = ['willa', 'racial']\n",
    "\n",
    "\n",
    "query_indxs = []\n",
    "sum_path = []\n",
    "for key in path_keys:\n",
    "    sum_path += merged_paths_dict[key]\n",
    "    query_indxs.append(merged_paths_dict[key][0])\n",
    "\n",
    "\n",
    "path_graph = dists_graph.subgraph(sum_path).copy()\n",
    "\n",
    "\n",
    "for u,v,d in path_graph.edges(data=True):\n",
    "    d['sim'] = 1 - d['weight']\n",
    "  \n",
    "for i in path_graph.nodes():\n",
    "    trace = trace_stem(indx2keyword_c[i])\n",
    "    if trace == 'query':\n",
    "        trace_color = '#d95f02'\n",
    "    elif trace == 'link':\n",
    "        trace_color = '#7570b3'\n",
    "    else:\n",
    "        trace_color = '#1b9e77'\n",
    "    path_graph.nodes[i]['keyword'] = stems_dictionary[indx2keyword_c[i]]\n",
    "    count = 0\n",
    "\n",
    "    for k in stems_dictionary[indx2keyword_c[i]]:\n",
    "        count += unigram_counts[k]\n",
    "        path_graph.node[i]['count'] = count\n",
    "        path_graph.nodes[i]['trace_color'] = trace_color\n",
    "        path_graph.nodes[i]['trace'] = trace\n",
    "        \n",
    "T=nx.minimum_spanning_tree(path_graph)\n",
    "\n",
    "json_results = build_keywords_tree(T, indx2keyword_c, stems_dictionary) \n",
    "# print(json_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2040,
     "resources": {
      "http://localhost:8080/static/components/requirejs/require.js": {
       "data": "/** vim: et:ts=4:sw=4:sts=4
 * @license RequireJS 2.1.22 Copyright (c) 2010-2015, The Dojo Foundation All Rights Reserved.
 * Available via the MIT or new BSD license.
 * see: http://github.com/jrburke/requirejs for details
 */
//Not using strict: uneven strict support in browsers, #392, and causes
//problems with requirejs.exec()/transpiler plugins that may not be strict.
/*jslint regexp: true, nomen: true, sloppy: true */
/*global window, navigator, document, importScripts, setTimeout, opera */

var requirejs, require, define;
(function (global) {
    var req, s, head, baseElement, dataMain, src,
        interactiveScript, currentlyAddingScript, mainScript, subPath,
        version = '2.1.22',
        commentRegExp = /(\/\*([\s\S]*?)\*\/|([^:]|^)\/\/(.*)$)/mg,
        cjsRequireRegExp = /[^.]\s*require\s*\(\s*["']([^'"\s]+)["']\s*\)/g,
        jsSuffixRegExp = /\.js$/,
        currDirRegExp = /^\.\//,
        op = Object.prototype,
        ostring = op.toString,
        hasOwn = op.hasOwnProperty,
        ap = Array.prototype,
        isBrowser = !!(typeof window !== 'undefined' && typeof navigator !== 'undefined' && window.document),
        isWebWorker = !isBrowser && typeof importScripts !== 'undefined',
        //PS3 indicates loaded and complete, but need to wait for complete
        //specifically. Sequence is 'loading', 'loaded', execution,
        // then 'complete'. The UA check is unfortunate, but not sure how
        //to feature test w/o causing perf issues.
        readyRegExp = isBrowser && navigator.platform === 'PLAYSTATION 3' ?
                      /^complete$/ : /^(complete|loaded)$/,
        defContextName = '_',
        //Oh the tragedy, detecting opera. See the usage of isOpera for reason.
        isOpera = typeof opera !== 'undefined' && opera.toString() === '[object Opera]',
        contexts = {},
        cfg = {},
        globalDefQueue = [],
        useInteractive = false;

    function isFunction(it) {
        return ostring.call(it) === '[object Function]';
    }

    function isArray(it) {
        return ostring.call(it) === '[object Array]';
    }

    /**
     * Helper function for iterating over an array. If the func returns
     * a true value, it will break out of the loop.
     */
    function each(ary, func) {
        if (ary) {
            var i;
            for (i = 0; i < ary.length; i += 1) {
                if (ary[i] && func(ary[i], i, ary)) {
                    break;
                }
            }
        }
    }

    /**
     * Helper function for iterating over an array backwards. If the func
     * returns a true value, it will break out of the loop.
     */
    function eachReverse(ary, func) {
        if (ary) {
            var i;
            for (i = ary.length - 1; i > -1; i -= 1) {
                if (ary[i] && func(ary[i], i, ary)) {
                    break;
                }
            }
        }
    }

    function hasProp(obj, prop) {
        return hasOwn.call(obj, prop);
    }

    function getOwn(obj, prop) {
        return hasProp(obj, prop) && obj[prop];
    }

    /**
     * Cycles over properties in an object and calls a function for each
     * property value. If the function returns a truthy value, then the
     * iteration is stopped.
     */
    function eachProp(obj, func) {
        var prop;
        for (prop in obj) {
            if (hasProp(obj, prop)) {
                if (func(obj[prop], prop)) {
                    break;
                }
            }
        }
    }

    /**
     * Simple function to mix in properties from source into target,
     * but only if target does not already have a property of the same name.
     */
    function mixin(target, source, force, deepStringMixin) {
        if (source) {
            eachProp(source, function (value, prop) {
                if (force || !hasProp(target, prop)) {
                    if (deepStringMixin && typeof value === 'object' && value &&
                        !isArray(value) && !isFunction(value) &&
                        !(value instanceof RegExp)) {

                        if (!target[prop]) {
                            target[prop] = {};
                        }
                        mixin(target[prop], value, force, deepStringMixin);
                    } else {
                        target[prop] = value;
                    }
                }
            });
        }
        return target;
    }

    //Similar to Function.prototype.bind, but the 'this' object is specified
    //first, since it is easier to read/figure out what 'this' will be.
    function bind(obj, fn) {
        return function () {
            return fn.apply(obj, arguments);
        };
    }

    function scripts() {
        return document.getElementsByTagName('script');
    }

    function defaultOnError(err) {
        throw err;
    }

    //Allow getting a global that is expressed in
    //dot notation, like 'a.b.c'.
    function getGlobal(value) {
        if (!value) {
            return value;
        }
        var g = global;
        each(value.split('.'), function (part) {
            g = g[part];
        });
        return g;
    }

    /**
     * Constructs an error with a pointer to an URL with more information.
     * @param {String} id the error ID that maps to an ID on a web page.
     * @param {String} message human readable error.
     * @param {Error} [err] the original error, if there is one.
     *
     * @returns {Error}
     */
    function makeError(id, msg, err, requireModules) {
        var e = new Error(msg + '\nhttp://requirejs.org/docs/errors.html#' + id);
        e.requireType = id;
        e.requireModules = requireModules;
        if (err) {
            e.originalError = err;
        }
        return e;
    }

    if (typeof define !== 'undefined') {
        //If a define is already in play via another AMD loader,
        //do not overwrite.
        return;
    }

    if (typeof requirejs !== 'undefined') {
        if (isFunction(requirejs)) {
            //Do not overwrite an existing requirejs instance.
            return;
        }
        cfg = requirejs;
        requirejs = undefined;
    }

    //Allow for a require config object
    if (typeof require !== 'undefined' && !isFunction(require)) {
        //assume it is a config object.
        cfg = require;
        require = undefined;
    }

    function newContext(contextName) {
        var inCheckLoaded, Module, context, handlers,
            checkLoadedTimeoutId,
            config = {
                //Defaults. Do not set a default for map
                //config to speed up normalize(), which
                //will run faster if there is no default.
                waitSeconds: 7,
                baseUrl: './',
                paths: {},
                bundles: {},
                pkgs: {},
                shim: {},
                config: {}
            },
            registry = {},
            //registry of just enabled modules, to speed
            //cycle breaking code when lots of modules
            //are registered, but not activated.
            enabledRegistry = {},
            undefEvents = {},
            defQueue = [],
            defined = {},
            urlFetched = {},
            bundlesMap = {},
            requireCounter = 1,
            unnormalizedCounter = 1;

        /**
         * Trims the . and .. from an array of path segments.
         * It will keep a leading path segment if a .. will become
         * the first path segment, to help with module name lookups,
         * which act like paths, but can be remapped. But the end result,
         * all paths that use this function should look normalized.
         * NOTE: this method MODIFIES the input array.
         * @param {Array} ary the array of path segments.
         */
        function trimDots(ary) {
            var i, part;
            for (i = 0; i < ary.length; i++) {
                part = ary[i];
                if (part === '.') {
                    ary.splice(i, 1);
                    i -= 1;
                } else if (part === '..') {
                    // If at the start, or previous value is still ..,
                    // keep them so that when converted to a path it may
                    // still work when converted to a path, even though
                    // as an ID it is less than ideal. In larger point
                    // releases, may be better to just kick out an error.
                    if (i === 0 || (i === 1 && ary[2] === '..') || ary[i - 1] === '..') {
                        continue;
                    } else if (i > 0) {
                        ary.splice(i - 1, 2);
                        i -= 2;
                    }
                }
            }
        }

        /**
         * Given a relative module name, like ./something, normalize it to
         * a real name that can be mapped to a path.
         * @param {String} name the relative name
         * @param {String} baseName a real name that the name arg is relative
         * to.
         * @param {Boolean} applyMap apply the map config to the value. Should
         * only be done if this normalization is for a dependency ID.
         * @returns {String} normalized name
         */
        function normalize(name, baseName, applyMap) {
            var pkgMain, mapValue, nameParts, i, j, nameSegment, lastIndex,
                foundMap, foundI, foundStarMap, starI, normalizedBaseParts,
                baseParts = (baseName && baseName.split('/')),
                map = config.map,
                starMap = map && map['*'];

            //Adjust any relative paths.
            if (name) {
                name = name.split('/');
                lastIndex = name.length - 1;

                // If wanting node ID compatibility, strip .js from end
                // of IDs. Have to do this here, and not in nameToUrl
                // because node allows either .js or non .js to map
                // to same file.
                if (config.nodeIdCompat && jsSuffixRegExp.test(name[lastIndex])) {
                    name[lastIndex] = name[lastIndex].replace(jsSuffixRegExp, '');
                }

                // Starts with a '.' so need the baseName
                if (name[0].charAt(0) === '.' && baseParts) {
                    //Convert baseName to array, and lop off the last part,
                    //so that . matches that 'directory' and not name of the baseName's
                    //module. For instance, baseName of 'one/two/three', maps to
                    //'one/two/three.js', but we want the directory, 'one/two' for
                    //this normalization.
                    normalizedBaseParts = baseParts.slice(0, baseParts.length - 1);
                    name = normalizedBaseParts.concat(name);
                }

                trimDots(name);
                name = name.join('/');
            }

            //Apply map config if available.
            if (applyMap && map && (baseParts || starMap)) {
                nameParts = name.split('/');

                outerLoop: for (i = nameParts.length; i > 0; i -= 1) {
                    nameSegment = nameParts.slice(0, i).join('/');

                    if (baseParts) {
                        //Find the longest baseName segment match in the config.
                        //So, do joins on the biggest to smallest lengths of baseParts.
                        for (j = baseParts.length; j > 0; j -= 1) {
                            mapValue = getOwn(map, baseParts.slice(0, j).join('/'));

                            //baseName segment has config, find if it has one for
                            //this name.
                            if (mapValue) {
                                mapValue = getOwn(mapValue, nameSegment);
                                if (mapValue) {
                                    //Match, update name to the new value.
                                    foundMap = mapValue;
                                    foundI = i;
                                    break outerLoop;
                                }
                            }
                        }
                    }

                    //Check for a star map match, but just hold on to it,
                    //if there is a shorter segment match later in a matching
                    //config, then favor over this star map.
                    if (!foundStarMap && starMap && getOwn(starMap, nameSegment)) {
                        foundStarMap = getOwn(starMap, nameSegment);
                        starI = i;
                    }
                }

                if (!foundMap && foundStarMap) {
                    foundMap = foundStarMap;
                    foundI = starI;
                }

                if (foundMap) {
                    nameParts.splice(0, foundI, foundMap);
                    name = nameParts.join('/');
                }
            }

            // If the name points to a package's name, use
            // the package main instead.
            pkgMain = getOwn(config.pkgs, name);

            return pkgMain ? pkgMain : name;
        }

        function removeScript(name) {
            if (isBrowser) {
                each(scripts(), function (scriptNode) {
                    if (scriptNode.getAttribute('data-requiremodule') === name &&
                            scriptNode.getAttribute('data-requirecontext') === context.contextName) {
                        scriptNode.parentNode.removeChild(scriptNode);
                        return true;
                    }
                });
            }
        }

        function hasPathFallback(id) {
            var pathConfig = getOwn(config.paths, id);
            if (pathConfig && isArray(pathConfig) && pathConfig.length > 1) {
                //Pop off the first array value, since it failed, and
                //retry
                pathConfig.shift();
                context.require.undef(id);

                //Custom require that does not do map translation, since
                //ID is "absolute", already mapped/resolved.
                context.makeRequire(null, {
                    skipMap: true
                })([id]);

                return true;
            }
        }

        //Turns a plugin!resource to [plugin, resource]
        //with the plugin being undefined if the name
        //did not have a plugin prefix.
        function splitPrefix(name) {
            var prefix,
                index = name ? name.indexOf('!') : -1;
            if (index > -1) {
                prefix = name.substring(0, index);
                name = name.substring(index + 1, name.length);
            }
            return [prefix, name];
        }

        /**
         * Creates a module mapping that includes plugin prefix, module
         * name, and path. If parentModuleMap is provided it will
         * also normalize the name via require.normalize()
         *
         * @param {String} name the module name
         * @param {String} [parentModuleMap] parent module map
         * for the module name, used to resolve relative names.
         * @param {Boolean} isNormalized: is the ID already normalized.
         * This is true if this call is done for a define() module ID.
         * @param {Boolean} applyMap: apply the map config to the ID.
         * Should only be true if this map is for a dependency.
         *
         * @returns {Object}
         */
        function makeModuleMap(name, parentModuleMap, isNormalized, applyMap) {
            var url, pluginModule, suffix, nameParts,
                prefix = null,
                parentName = parentModuleMap ? parentModuleMap.name : null,
                originalName = name,
                isDefine = true,
                normalizedName = '';

            //If no name, then it means it is a require call, generate an
            //internal name.
            if (!name) {
                isDefine = false;
                name = '_@r' + (requireCounter += 1);
            }

            nameParts = splitPrefix(name);
            prefix = nameParts[0];
            name = nameParts[1];

            if (prefix) {
                prefix = normalize(prefix, parentName, applyMap);
                pluginModule = getOwn(defined, prefix);
            }

            //Account for relative paths if there is a base name.
            if (name) {
                if (prefix) {
                    if (pluginModule && pluginModule.normalize) {
                        //Plugin is loaded, use its normalize method.
                        normalizedName = pluginModule.normalize(name, function (name) {
                            return normalize(name, parentName, applyMap);
                        });
                    } else {
                        // If nested plugin references, then do not try to
                        // normalize, as it will not normalize correctly. This
                        // places a restriction on resourceIds, and the longer
                        // term solution is not to normalize until plugins are
                        // loaded and all normalizations to allow for async
                        // loading of a loader plugin. But for now, fixes the
                        // common uses. Details in #1131
                        normalizedName = name.indexOf('!') === -1 ?
                                         normalize(name, parentName, applyMap) :
                                         name;
                    }
                } else {
                    //A regular module.
                    normalizedName = normalize(name, parentName, applyMap);

                    //Normalized name may be a plugin ID due to map config
                    //application in normalize. The map config values must
                    //already be normalized, so do not need to redo that part.
                    nameParts = splitPrefix(normalizedName);
                    prefix = nameParts[0];
                    normalizedName = nameParts[1];
                    isNormalized = true;

                    url = context.nameToUrl(normalizedName);
                }
            }

            //If the id is a plugin id that cannot be determined if it needs
            //normalization, stamp it with a unique ID so two matching relative
            //ids that may conflict can be separate.
            suffix = prefix && !pluginModule && !isNormalized ?
                     '_unnormalized' + (unnormalizedCounter += 1) :
                     '';

            return {
                prefix: prefix,
                name: normalizedName,
                parentMap: parentModuleMap,
                unnormalized: !!suffix,
                url: url,
                originalName: originalName,
                isDefine: isDefine,
                id: (prefix ?
                        prefix + '!' + normalizedName :
                        normalizedName) + suffix
            };
        }

        function getModule(depMap) {
            var id = depMap.id,
                mod = getOwn(registry, id);

            if (!mod) {
                mod = registry[id] = new context.Module(depMap);
            }

            return mod;
        }

        function on(depMap, name, fn) {
            var id = depMap.id,
                mod = getOwn(registry, id);

            if (hasProp(defined, id) &&
                    (!mod || mod.defineEmitComplete)) {
                if (name === 'defined') {
                    fn(defined[id]);
                }
            } else {
                mod = getModule(depMap);
                if (mod.error && name === 'error') {
                    fn(mod.error);
                } else {
                    mod.on(name, fn);
                }
            }
        }

        function onError(err, errback) {
            var ids = err.requireModules,
                notified = false;

            if (errback) {
                errback(err);
            } else {
                each(ids, function (id) {
                    var mod = getOwn(registry, id);
                    if (mod) {
                        //Set error on module, so it skips timeout checks.
                        mod.error = err;
                        if (mod.events.error) {
                            notified = true;
                            mod.emit('error', err);
                        }
                    }
                });

                if (!notified) {
                    req.onError(err);
                }
            }
        }

        /**
         * Internal method to transfer globalQueue items to this context's
         * defQueue.
         */
        function takeGlobalQueue() {
            //Push all the globalDefQueue items into the context's defQueue
            if (globalDefQueue.length) {
                each(globalDefQueue, function(queueItem) {
                    var id = queueItem[0];
                    if (typeof id === 'string') {
                        context.defQueueMap[id] = true;
                    }
                    defQueue.push(queueItem);
                });
                globalDefQueue = [];
            }
        }

        handlers = {
            'require': function (mod) {
                if (mod.require) {
                    return mod.require;
                } else {
                    return (mod.require = context.makeRequire(mod.map));
                }
            },
            'exports': function (mod) {
                mod.usingExports = true;
                if (mod.map.isDefine) {
                    if (mod.exports) {
                        return (defined[mod.map.id] = mod.exports);
                    } else {
                        return (mod.exports = defined[mod.map.id] = {});
                    }
                }
            },
            'module': function (mod) {
                if (mod.module) {
                    return mod.module;
                } else {
                    return (mod.module = {
                        id: mod.map.id,
                        uri: mod.map.url,
                        config: function () {
                            return getOwn(config.config, mod.map.id) || {};
                        },
                        exports: mod.exports || (mod.exports = {})
                    });
                }
            }
        };

        function cleanRegistry(id) {
            //Clean up machinery used for waiting modules.
            delete registry[id];
            delete enabledRegistry[id];
        }

        function breakCycle(mod, traced, processed) {
            var id = mod.map.id;

            if (mod.error) {
                mod.emit('error', mod.error);
            } else {
                traced[id] = true;
                each(mod.depMaps, function (depMap, i) {
                    var depId = depMap.id,
                        dep = getOwn(registry, depId);

                    //Only force things that have not completed
                    //being defined, so still in the registry,
                    //and only if it has not been matched up
                    //in the module already.
                    if (dep && !mod.depMatched[i] && !processed[depId]) {
                        if (getOwn(traced, depId)) {
                            mod.defineDep(i, defined[depId]);
                            mod.check(); //pass false?
                        } else {
                            breakCycle(dep, traced, processed);
                        }
                    }
                });
                processed[id] = true;
            }
        }

        function checkLoaded() {
            var err, usingPathFallback,
                waitInterval = config.waitSeconds * 1000,
                //It is possible to disable the wait interval by using waitSeconds of 0.
                expired = waitInterval && (context.startTime + waitInterval) < new Date().getTime(),
                noLoads = [],
                reqCalls = [],
                stillLoading = false,
                needCycleCheck = true;

            //Do not bother if this call was a result of a cycle break.
            if (inCheckLoaded) {
                return;
            }

            inCheckLoaded = true;

            //Figure out the state of all the modules.
            eachProp(enabledRegistry, function (mod) {
                var map = mod.map,
                    modId = map.id;

                //Skip things that are not enabled or in error state.
                if (!mod.enabled) {
                    return;
                }

                if (!map.isDefine) {
                    reqCalls.push(mod);
                }

                if (!mod.error) {
                    //If the module should be executed, and it has not
                    //been inited and time is up, remember it.
                    if (!mod.inited && expired) {
                        if (hasPathFallback(modId)) {
                            usingPathFallback = true;
                            stillLoading = true;
                        } else {
                            noLoads.push(modId);
                            removeScript(modId);
                        }
                    } else if (!mod.inited && mod.fetched && map.isDefine) {
                        stillLoading = true;
                        if (!map.prefix) {
                            //No reason to keep looking for unfinished
                            //loading. If the only stillLoading is a
                            //plugin resource though, keep going,
                            //because it may be that a plugin resource
                            //is waiting on a non-plugin cycle.
                            return (needCycleCheck = false);
                        }
                    }
                }
            });

            if (expired && noLoads.length) {
                //If wait time expired, throw error of unloaded modules.
                err = makeError('timeout', 'Load timeout for modules: ' + noLoads, null, noLoads);
                err.contextName = context.contextName;
                return onError(err);
            }

            //Not expired, check for a cycle.
            if (needCycleCheck) {
                each(reqCalls, function (mod) {
                    breakCycle(mod, {}, {});
                });
            }

            //If still waiting on loads, and the waiting load is something
            //other than a plugin resource, or there are still outstanding
            //scripts, then just try back later.
            if ((!expired || usingPathFallback) && stillLoading) {
                //Something is still waiting to load. Wait for it, but only
                //if a timeout is not already in effect.
                if ((isBrowser || isWebWorker) && !checkLoadedTimeoutId) {
                    checkLoadedTimeoutId = setTimeout(function () {
                        checkLoadedTimeoutId = 0;
                        checkLoaded();
                    }, 50);
                }
            }

            inCheckLoaded = false;
        }

        Module = function (map) {
            this.events = getOwn(undefEvents, map.id) || {};
            this.map = map;
            this.shim = getOwn(config.shim, map.id);
            this.depExports = [];
            this.depMaps = [];
            this.depMatched = [];
            this.pluginMaps = {};
            this.depCount = 0;

            /* this.exports this.factory
               this.depMaps = [],
               this.enabled, this.fetched
            */
        };

        Module.prototype = {
            init: function (depMaps, factory, errback, options) {
                options = options || {};

                //Do not do more inits if already done. Can happen if there
                //are multiple define calls for the same module. That is not
                //a normal, common case, but it is also not unexpected.
                if (this.inited) {
                    return;
                }

                this.factory = factory;

                if (errback) {
                    //Register for errors on this module.
                    this.on('error', errback);
                } else if (this.events.error) {
                    //If no errback already, but there are error listeners
                    //on this module, set up an errback to pass to the deps.
                    errback = bind(this, function (err) {
                        this.emit('error', err);
                    });
                }

                //Do a copy of the dependency array, so that
                //source inputs are not modified. For example
                //"shim" deps are passed in here directly, and
                //doing a direct modification of the depMaps array
                //would affect that config.
                this.depMaps = depMaps && depMaps.slice(0);

                this.errback = errback;

                //Indicate this module has be initialized
                this.inited = true;

                this.ignore = options.ignore;

                //Could have option to init this module in enabled mode,
                //or could have been previously marked as enabled. However,
                //the dependencies are not known until init is called. So
                //if enabled previously, now trigger dependencies as enabled.
                if (options.enabled || this.enabled) {
                    //Enable this module and dependencies.
                    //Will call this.check()
                    this.enable();
                } else {
                    this.check();
                }
            },

            defineDep: function (i, depExports) {
                //Because of cycles, defined callback for a given
                //export can be called more than once.
                if (!this.depMatched[i]) {
                    this.depMatched[i] = true;
                    this.depCount -= 1;
                    this.depExports[i] = depExports;
                }
            },

            fetch: function () {
                if (this.fetched) {
                    return;
                }
                this.fetched = true;

                context.startTime = (new Date()).getTime();

                var map = this.map;

                //If the manager is for a plugin managed resource,
                //ask the plugin to load it now.
                if (this.shim) {
                    context.makeRequire(this.map, {
                        enableBuildCallback: true
                    })(this.shim.deps || [], bind(this, function () {
                        return map.prefix ? this.callPlugin() : this.load();
                    }));
                } else {
                    //Regular dependency.
                    return map.prefix ? this.callPlugin() : this.load();
                }
            },

            load: function () {
                var url = this.map.url;

                //Regular dependency.
                if (!urlFetched[url]) {
                    urlFetched[url] = true;
                    context.load(this.map.id, url);
                }
            },

            /**
             * Checks if the module is ready to define itself, and if so,
             * define it.
             */
            check: function () {
                if (!this.enabled || this.enabling) {
                    return;
                }

                var err, cjsModule,
                    id = this.map.id,
                    depExports = this.depExports,
                    exports = this.exports,
                    factory = this.factory;

                if (!this.inited) {
                    // Only fetch if not already in the defQueue.
                    if (!hasProp(context.defQueueMap, id)) {
                        this.fetch();
                    }
                } else if (this.error) {
                    this.emit('error', this.error);
                } else if (!this.defining) {
                    //The factory could trigger another require call
                    //that would result in checking this module to
                    //define itself again. If already in the process
                    //of doing that, skip this work.
                    this.defining = true;

                    if (this.depCount < 1 && !this.defined) {
                        if (isFunction(factory)) {
                            try {
                                exports = context.execCb(id, factory, depExports, exports);
                            } catch (e) {
                                err = e;
                            }

                            // Favor return value over exports. If node/cjs in play,
                            // then will not have a return value anyway. Favor
                            // module.exports assignment over exports object.
                            if (this.map.isDefine && exports === undefined) {
                                cjsModule = this.module;
                                if (cjsModule) {
                                    exports = cjsModule.exports;
                                } else if (this.usingExports) {
                                    //exports already set the defined value.
                                    exports = this.exports;
                                }
                            }

                            if (err) {
                                // If there is an error listener, favor passing
                                // to that instead of throwing an error. However,
                                // only do it for define()'d  modules. require
                                // errbacks should not be called for failures in
                                // their callbacks (#699). However if a global
                                // onError is set, use that.
                                if ((this.events.error && this.map.isDefine) ||
                                    req.onError !== defaultOnError) {
                                    err.requireMap = this.map;
                                    err.requireModules = this.map.isDefine ? [this.map.id] : null;
                                    err.requireType = this.map.isDefine ? 'define' : 'require';
                                    return onError((this.error = err));
                                } else if (typeof console !== 'undefined' &&
                                           console.error) {
                                    // Log the error for debugging. If promises could be
                                    // used, this would be different, but making do.
                                    console.error(err);
                                } else {
                                    // Do not want to completely lose the error. While this
                                    // will mess up processing and lead to similar results
                                    // as bug 1440, it at least surfaces the error.
                                    req.onError(err);
                                }
                            }
                        } else {
                            //Just a literal value
                            exports = factory;
                        }

                        this.exports = exports;

                        if (this.map.isDefine && !this.ignore) {
                            defined[id] = exports;

                            if (req.onResourceLoad) {
                                var resLoadMaps = [];
                                each(this.depMaps, function (depMap) {
                                    resLoadMaps.push(depMap.normalizedMap || depMap);
                                });
                                req.onResourceLoad(context, this.map, resLoadMaps);
                            }
                        }

                        //Clean up
                        cleanRegistry(id);

                        this.defined = true;
                    }

                    //Finished the define stage. Allow calling check again
                    //to allow define notifications below in the case of a
                    //cycle.
                    this.defining = false;

                    if (this.defined && !this.defineEmitted) {
                        this.defineEmitted = true;
                        this.emit('defined', this.exports);
                        this.defineEmitComplete = true;
                    }

                }
            },

            callPlugin: function () {
                var map = this.map,
                    id = map.id,
                    //Map already normalized the prefix.
                    pluginMap = makeModuleMap(map.prefix);

                //Mark this as a dependency for this plugin, so it
                //can be traced for cycles.
                this.depMaps.push(pluginMap);

                on(pluginMap, 'defined', bind(this, function (plugin) {
                    var load, normalizedMap, normalizedMod,
                        bundleId = getOwn(bundlesMap, this.map.id),
                        name = this.map.name,
                        parentName = this.map.parentMap ? this.map.parentMap.name : null,
                        localRequire = context.makeRequire(map.parentMap, {
                            enableBuildCallback: true
                        });

                    //If current map is not normalized, wait for that
                    //normalized name to load instead of continuing.
                    if (this.map.unnormalized) {
                        //Normalize the ID if the plugin allows it.
                        if (plugin.normalize) {
                            name = plugin.normalize(name, function (name) {
                                return normalize(name, parentName, true);
                            }) || '';
                        }

                        //prefix and name should already be normalized, no need
                        //for applying map config again either.
                        normalizedMap = makeModuleMap(map.prefix + '!' + name,
                                                      this.map.parentMap);
                        on(normalizedMap,
                            'defined', bind(this, function (value) {
                                this.map.normalizedMap = normalizedMap;
                                this.init([], function () { return value; }, null, {
                                    enabled: true,
                                    ignore: true
                                });
                            }));

                        normalizedMod = getOwn(registry, normalizedMap.id);
                        if (normalizedMod) {
                            //Mark this as a dependency for this plugin, so it
                            //can be traced for cycles.
                            this.depMaps.push(normalizedMap);

                            if (this.events.error) {
                                normalizedMod.on('error', bind(this, function (err) {
                                    this.emit('error', err);
                                }));
                            }
                            normalizedMod.enable();
                        }

                        return;
                    }

                    //If a paths config, then just load that file instead to
                    //resolve the plugin, as it is built into that paths layer.
                    if (bundleId) {
                        this.map.url = context.nameToUrl(bundleId);
                        this.load();
                        return;
                    }

                    load = bind(this, function (value) {
                        this.init([], function () { return value; }, null, {
                            enabled: true
                        });
                    });

                    load.error = bind(this, function (err) {
                        this.inited = true;
                        this.error = err;
                        err.requireModules = [id];

                        //Remove temp unnormalized modules for this module,
                        //since they will never be resolved otherwise now.
                        eachProp(registry, function (mod) {
                            if (mod.map.id.indexOf(id + '_unnormalized') === 0) {
                                cleanRegistry(mod.map.id);
                            }
                        });

                        onError(err);
                    });

                    //Allow plugins to load other code without having to know the
                    //context or how to 'complete' the load.
                    load.fromText = bind(this, function (text, textAlt) {
                        /*jslint evil: true */
                        var moduleName = map.name,
                            moduleMap = makeModuleMap(moduleName),
                            hasInteractive = useInteractive;

                        //As of 2.1.0, support just passing the text, to reinforce
                        //fromText only being called once per resource. Still
                        //support old style of passing moduleName but discard
                        //that moduleName in favor of the internal ref.
                        if (textAlt) {
                            text = textAlt;
                        }

                        //Turn off interactive script matching for IE for any define
                        //calls in the text, then turn it back on at the end.
                        if (hasInteractive) {
                            useInteractive = false;
                        }

                        //Prime the system by creating a module instance for
                        //it.
                        getModule(moduleMap);

                        //Transfer any config to this other module.
                        if (hasProp(config.config, id)) {
                            config.config[moduleName] = config.config[id];
                        }

                        try {
                            req.exec(text);
                        } catch (e) {
                            return onError(makeError('fromtexteval',
                                             'fromText eval for ' + id +
                                            ' failed: ' + e,
                                             e,
                                             [id]));
                        }

                        if (hasInteractive) {
                            useInteractive = true;
                        }

                        //Mark this as a dependency for the plugin
                        //resource
                        this.depMaps.push(moduleMap);

                        //Support anonymous modules.
                        context.completeLoad(moduleName);

                        //Bind the value of that module to the value for this
                        //resource ID.
                        localRequire([moduleName], load);
                    });

                    //Use parentName here since the plugin's name is not reliable,
                    //could be some weird string with no path that actually wants to
                    //reference the parentName's path.
                    plugin.load(map.name, localRequire, load, config);
                }));

                context.enable(pluginMap, this);
                this.pluginMaps[pluginMap.id] = pluginMap;
            },

            enable: function () {
                enabledRegistry[this.map.id] = this;
                this.enabled = true;

                //Set flag mentioning that the module is enabling,
                //so that immediate calls to the defined callbacks
                //for dependencies do not trigger inadvertent load
                //with the depCount still being zero.
                this.enabling = true;

                //Enable each dependency
                each(this.depMaps, bind(this, function (depMap, i) {
                    var id, mod, handler;

                    if (typeof depMap === 'string') {
                        //Dependency needs to be converted to a depMap
                        //and wired up to this module.
                        depMap = makeModuleMap(depMap,
                                               (this.map.isDefine ? this.map : this.map.parentMap),
                                               false,
                                               !this.skipMap);
                        this.depMaps[i] = depMap;

                        handler = getOwn(handlers, depMap.id);

                        if (handler) {
                            this.depExports[i] = handler(this);
                            return;
                        }

                        this.depCount += 1;

                        on(depMap, 'defined', bind(this, function (depExports) {
                            if (this.undefed) {
                                return;
                            }
                            this.defineDep(i, depExports);
                            this.check();
                        }));

                        if (this.errback) {
                            on(depMap, 'error', bind(this, this.errback));
                        } else if (this.events.error) {
                            // No direct errback on this module, but something
                            // else is listening for errors, so be sure to
                            // propagate the error correctly.
                            on(depMap, 'error', bind(this, function(err) {
                                this.emit('error', err);
                            }));
                        }
                    }

                    id = depMap.id;
                    mod = registry[id];

                    //Skip special modules like 'require', 'exports', 'module'
                    //Also, don't call enable if it is already enabled,
                    //important in circular dependency cases.
                    if (!hasProp(handlers, id) && mod && !mod.enabled) {
                        context.enable(depMap, this);
                    }
                }));

                //Enable each plugin that is used in
                //a dependency
                eachProp(this.pluginMaps, bind(this, function (pluginMap) {
                    var mod = getOwn(registry, pluginMap.id);
                    if (mod && !mod.enabled) {
                        context.enable(pluginMap, this);
                    }
                }));

                this.enabling = false;

                this.check();
            },

            on: function (name, cb) {
                var cbs = this.events[name];
                if (!cbs) {
                    cbs = this.events[name] = [];
                }
                cbs.push(cb);
            },

            emit: function (name, evt) {
                each(this.events[name], function (cb) {
                    cb(evt);
                });
                if (name === 'error') {
                    //Now that the error handler was triggered, remove
                    //the listeners, since this broken Module instance
                    //can stay around for a while in the registry.
                    delete this.events[name];
                }
            }
        };

        function callGetModule(args) {
            //Skip modules already defined.
            if (!hasProp(defined, args[0])) {
                getModule(makeModuleMap(args[0], null, true)).init(args[1], args[2]);
            }
        }

        function removeListener(node, func, name, ieName) {
            //Favor detachEvent because of IE9
            //issue, see attachEvent/addEventListener comment elsewhere
            //in this file.
            if (node.detachEvent && !isOpera) {
                //Probably IE. If not it will throw an error, which will be
                //useful to know.
                if (ieName) {
                    node.detachEvent(ieName, func);
                }
            } else {
                node.removeEventListener(name, func, false);
            }
        }

        /**
         * Given an event from a script node, get the requirejs info from it,
         * and then removes the event listeners on the node.
         * @param {Event} evt
         * @returns {Object}
         */
        function getScriptData(evt) {
            //Using currentTarget instead of target for Firefox 2.0's sake. Not
            //all old browsers will be supported, but this one was easy enough
            //to support and still makes sense.
            var node = evt.currentTarget || evt.srcElement;

            //Remove the listeners once here.
            removeListener(node, context.onScriptLoad, 'load', 'onreadystatechange');
            removeListener(node, context.onScriptError, 'error');

            return {
                node: node,
                id: node && node.getAttribute('data-requiremodule')
            };
        }

        function intakeDefines() {
            var args;

            //Any defined modules in the global queue, intake them now.
            takeGlobalQueue();

            //Make sure any remaining defQueue items get properly processed.
            while (defQueue.length) {
                args = defQueue.shift();
                if (args[0] === null) {
                    return onError(makeError('mismatch', 'Mismatched anonymous define() module: ' +
                        args[args.length - 1]));
                } else {
                    //args are id, deps, factory. Should be normalized by the
                    //define() function.
                    callGetModule(args);
                }
            }
            context.defQueueMap = {};
        }

        context = {
            config: config,
            contextName: contextName,
            registry: registry,
            defined: defined,
            urlFetched: urlFetched,
            defQueue: defQueue,
            defQueueMap: {},
            Module: Module,
            makeModuleMap: makeModuleMap,
            nextTick: req.nextTick,
            onError: onError,

            /**
             * Set a configuration for the context.
             * @param {Object} cfg config object to integrate.
             */
            configure: function (cfg) {
                //Make sure the baseUrl ends in a slash.
                if (cfg.baseUrl) {
                    if (cfg.baseUrl.charAt(cfg.baseUrl.length - 1) !== '/') {
                        cfg.baseUrl += '/';
                    }
                }

                //Save off the paths since they require special processing,
                //they are additive.
                var shim = config.shim,
                    objs = {
                        paths: true,
                        bundles: true,
                        config: true,
                        map: true
                    };

                eachProp(cfg, function (value, prop) {
                    if (objs[prop]) {
                        if (!config[prop]) {
                            config[prop] = {};
                        }
                        mixin(config[prop], value, true, true);
                    } else {
                        config[prop] = value;
                    }
                });

                //Reverse map the bundles
                if (cfg.bundles) {
                    eachProp(cfg.bundles, function (value, prop) {
                        each(value, function (v) {
                            if (v !== prop) {
                                bundlesMap[v] = prop;
                            }
                        });
                    });
                }

                //Merge shim
                if (cfg.shim) {
                    eachProp(cfg.shim, function (value, id) {
                        //Normalize the structure
                        if (isArray(value)) {
                            value = {
                                deps: value
                            };
                        }
                        if ((value.exports || value.init) && !value.exportsFn) {
                            value.exportsFn = context.makeShimExports(value);
                        }
                        shim[id] = value;
                    });
                    config.shim = shim;
                }

                //Adjust packages if necessary.
                if (cfg.packages) {
                    each(cfg.packages, function (pkgObj) {
                        var location, name;

                        pkgObj = typeof pkgObj === 'string' ? {name: pkgObj} : pkgObj;

                        name = pkgObj.name;
                        location = pkgObj.location;
                        if (location) {
                            config.paths[name] = pkgObj.location;
                        }

                        //Save pointer to main module ID for pkg name.
                        //Remove leading dot in main, so main paths are normalized,
                        //and remove any trailing .js, since different package
                        //envs have different conventions: some use a module name,
                        //some use a file name.
                        config.pkgs[name] = pkgObj.name + '/' + (pkgObj.main || 'main')
                                     .replace(currDirRegExp, '')
                                     .replace(jsSuffixRegExp, '');
                    });
                }

                //If there are any "waiting to execute" modules in the registry,
                //update the maps for them, since their info, like URLs to load,
                //may have changed.
                eachProp(registry, function (mod, id) {
                    //If module already has init called, since it is too
                    //late to modify them, and ignore unnormalized ones
                    //since they are transient.
                    if (!mod.inited && !mod.map.unnormalized) {
                        mod.map = makeModuleMap(id, null, true);
                    }
                });

                //If a deps array or a config callback is specified, then call
                //require with those args. This is useful when require is defined as a
                //config object before require.js is loaded.
                if (cfg.deps || cfg.callback) {
                    context.require(cfg.deps || [], cfg.callback);
                }
            },

            makeShimExports: function (value) {
                function fn() {
                    var ret;
                    if (value.init) {
                        ret = value.init.apply(global, arguments);
                    }
                    return ret || (value.exports && getGlobal(value.exports));
                }
                return fn;
            },

            makeRequire: function (relMap, options) {
                options = options || {};

                function localRequire(deps, callback, errback) {
                    var id, map, requireMod;

                    if (options.enableBuildCallback && callback && isFunction(callback)) {
                        callback.__requireJsBuild = true;
                    }

                    if (typeof deps === 'string') {
                        if (isFunction(callback)) {
                            //Invalid call
                            return onError(makeError('requireargs', 'Invalid require call'), errback);
                        }

                        //If require|exports|module are requested, get the
                        //value for them from the special handlers. Caveat:
                        //this only works while module is being defined.
                        if (relMap && hasProp(handlers, deps)) {
                            return handlers[deps](registry[relMap.id]);
                        }

                        //Synchronous access to one module. If require.get is
                        //available (as in the Node adapter), prefer that.
                        if (req.get) {
                            return req.get(context, deps, relMap, localRequire);
                        }

                        //Normalize module name, if it contains . or ..
                        map = makeModuleMap(deps, relMap, false, true);
                        id = map.id;

                        if (!hasProp(defined, id)) {
                            return onError(makeError('notloaded', 'Module name "' +
                                        id +
                                        '" has not been loaded yet for context: ' +
                                        contextName +
                                        (relMap ? '' : '. Use require([])')));
                        }
                        return defined[id];
                    }

                    //Grab defines waiting in the global queue.
                    intakeDefines();

                    //Mark all the dependencies as needing to be loaded.
                    context.nextTick(function () {
                        //Some defines could have been added since the
                        //require call, collect them.
                        intakeDefines();

                        requireMod = getModule(makeModuleMap(null, relMap));

                        //Store if map config should be applied to this require
                        //call for dependencies.
                        requireMod.skipMap = options.skipMap;

                        requireMod.init(deps, callback, errback, {
                            enabled: true
                        });

                        checkLoaded();
                    });

                    return localRequire;
                }

                mixin(localRequire, {
                    isBrowser: isBrowser,

                    /**
                     * Converts a module name + .extension into an URL path.
                     * *Requires* the use of a module name. It does not support using
                     * plain URLs like nameToUrl.
                     */
                    toUrl: function (moduleNamePlusExt) {
                        var ext,
                            index = moduleNamePlusExt.lastIndexOf('.'),
                            segment = moduleNamePlusExt.split('/')[0],
                            isRelative = segment === '.' || segment === '..';

                        //Have a file extension alias, and it is not the
                        //dots from a relative path.
                        if (index !== -1 && (!isRelative || index > 1)) {
                            ext = moduleNamePlusExt.substring(index, moduleNamePlusExt.length);
                            moduleNamePlusExt = moduleNamePlusExt.substring(0, index);
                        }

                        return context.nameToUrl(normalize(moduleNamePlusExt,
                                                relMap && relMap.id, true), ext,  true);
                    },

                    defined: function (id) {
                        return hasProp(defined, makeModuleMap(id, relMap, false, true).id);
                    },

                    specified: function (id) {
                        id = makeModuleMap(id, relMap, false, true).id;
                        return hasProp(defined, id) || hasProp(registry, id);
                    }
                });

                //Only allow undef on top level require calls
                if (!relMap) {
                    localRequire.undef = function (id) {
                        //Bind any waiting define() calls to this context,
                        //fix for #408
                        takeGlobalQueue();

                        var map = makeModuleMap(id, relMap, true),
                            mod = getOwn(registry, id);

                        mod.undefed = true;
                        removeScript(id);

                        delete defined[id];
                        delete urlFetched[map.url];
                        delete undefEvents[id];

                        //Clean queued defines too. Go backwards
                        //in array so that the splices do not
                        //mess up the iteration.
                        eachReverse(defQueue, function(args, i) {
                            if (args[0] === id) {
                                defQueue.splice(i, 1);
                            }
                        });
                        delete context.defQueueMap[id];

                        if (mod) {
                            //Hold on to listeners in case the
                            //module will be attempted to be reloaded
                            //using a different config.
                            if (mod.events.defined) {
                                undefEvents[id] = mod.events;
                            }

                            cleanRegistry(id);
                        }
                    };
                }

                return localRequire;
            },

            /**
             * Called to enable a module if it is still in the registry
             * awaiting enablement. A second arg, parent, the parent module,
             * is passed in for context, when this method is overridden by
             * the optimizer. Not shown here to keep code compact.
             */
            enable: function (depMap) {
                var mod = getOwn(registry, depMap.id);
                if (mod) {
                    getModule(depMap).enable();
                }
            },

            /**
             * Internal method used by environment adapters to complete a load event.
             * A load event could be a script load or just a load pass from a synchronous
             * load call.
             * @param {String} moduleName the name of the module to potentially complete.
             */
            completeLoad: function (moduleName) {
                var found, args, mod,
                    shim = getOwn(config.shim, moduleName) || {},
                    shExports = shim.exports;

                takeGlobalQueue();

                while (defQueue.length) {
                    args = defQueue.shift();
                    if (args[0] === null) {
                        args[0] = moduleName;
                        //If already found an anonymous module and bound it
                        //to this name, then this is some other anon module
                        //waiting for its completeLoad to fire.
                        if (found) {
                            break;
                        }
                        found = true;
                    } else if (args[0] === moduleName) {
                        //Found matching define call for this script!
                        found = true;
                    }

                    callGetModule(args);
                }
                context.defQueueMap = {};

                //Do this after the cycle of callGetModule in case the result
                //of those calls/init calls changes the registry.
                mod = getOwn(registry, moduleName);

                if (!found && !hasProp(defined, moduleName) && mod && !mod.inited) {
                    if (config.enforceDefine && (!shExports || !getGlobal(shExports))) {
                        if (hasPathFallback(moduleName)) {
                            return;
                        } else {
                            return onError(makeError('nodefine',
                                             'No define call for ' + moduleName,
                                             null,
                                             [moduleName]));
                        }
                    } else {
                        //A script that does not call define(), so just simulate
                        //the call for it.
                        callGetModule([moduleName, (shim.deps || []), shim.exportsFn]);
                    }
                }

                checkLoaded();
            },

            /**
             * Converts a module name to a file path. Supports cases where
             * moduleName may actually be just an URL.
             * Note that it **does not** call normalize on the moduleName,
             * it is assumed to have already been normalized. This is an
             * internal API, not a public one. Use toUrl for the public API.
             */
            nameToUrl: function (moduleName, ext, skipExt) {
                var paths, syms, i, parentModule, url,
                    parentPath, bundleId,
                    pkgMain = getOwn(config.pkgs, moduleName);

                if (pkgMain) {
                    moduleName = pkgMain;
                }

                bundleId = getOwn(bundlesMap, moduleName);

                if (bundleId) {
                    return context.nameToUrl(bundleId, ext, skipExt);
                }

                //If a colon is in the URL, it indicates a protocol is used and it is just
                //an URL to a file, or if it starts with a slash, contains a query arg (i.e. ?)
                //or ends with .js, then assume the user meant to use an url and not a module id.
                //The slash is important for protocol-less URLs as well as full paths.
                if (req.jsExtRegExp.test(moduleName)) {
                    //Just a plain path, not module name lookup, so just return it.
                    //Add extension if it is included. This is a bit wonky, only non-.js things pass
                    //an extension, this method probably needs to be reworked.
                    url = moduleName + (ext || '');
                } else {
                    //A module that needs to be converted to a path.
                    paths = config.paths;

                    syms = moduleName.split('/');
                    //For each module name segment, see if there is a path
                    //registered for it. Start with most specific name
                    //and work up from it.
                    for (i = syms.length; i > 0; i -= 1) {
                        parentModule = syms.slice(0, i).join('/');

                        parentPath = getOwn(paths, parentModule);
                        if (parentPath) {
                            //If an array, it means there are a few choices,
                            //Choose the one that is desired
                            if (isArray(parentPath)) {
                                parentPath = parentPath[0];
                            }
                            syms.splice(0, i, parentPath);
                            break;
                        }
                    }

                    //Join the path parts together, then figure out if baseUrl is needed.
                    url = syms.join('/');
                    url += (ext || (/^data\:|\?/.test(url) || skipExt ? '' : '.js'));
                    url = (url.charAt(0) === '/' || url.match(/^[\w\+\.\-]+:/) ? '' : config.baseUrl) + url;
                }

                return config.urlArgs ? url +
                                        ((url.indexOf('?') === -1 ? '?' : '&') +
                                         config.urlArgs) : url;
            },

            //Delegates to req.load. Broken out as a separate function to
            //allow overriding in the optimizer.
            load: function (id, url) {
                req.load(context, id, url);
            },

            /**
             * Executes a module callback function. Broken out as a separate function
             * solely to allow the build system to sequence the files in the built
             * layer in the right sequence.
             *
             * @private
             */
            execCb: function (name, callback, args, exports) {
                return callback.apply(exports, args);
            },

            /**
             * callback for script loads, used to check status of loading.
             *
             * @param {Event} evt the event from the browser for the script
             * that was loaded.
             */
            onScriptLoad: function (evt) {
                //Using currentTarget instead of target for Firefox 2.0's sake. Not
                //all old browsers will be supported, but this one was easy enough
                //to support and still makes sense.
                if (evt.type === 'load' ||
                        (readyRegExp.test((evt.currentTarget || evt.srcElement).readyState))) {
                    //Reset interactive script so a script node is not held onto for
                    //to long.
                    interactiveScript = null;

                    //Pull out the name of the module and the context.
                    var data = getScriptData(evt);
                    context.completeLoad(data.id);
                }
            },

            /**
             * Callback for script errors.
             */
            onScriptError: function (evt) {
                var data = getScriptData(evt);
                if (!hasPathFallback(data.id)) {
                    var parents = [];
                    eachProp(registry, function(value, key) {
                        if (key.indexOf('_@r') !== 0) {
                            each(value.depMaps, function(depMap) {
                                if (depMap.id === data.id) {
                                    parents.push(key);
                                }
                                return true;
                            });
                        }
                    });
                    return onError(makeError('scripterror', 'Script error for "' + data.id +
                                             (parents.length ?
                                             '", needed by: ' + parents.join(', ') :
                                             '"'), evt, [data.id]));
                }
            }
        };

        context.require = context.makeRequire();
        return context;
    }

    /**
     * Main entry point.
     *
     * If the only argument to require is a string, then the module that
     * is represented by that string is fetched for the appropriate context.
     *
     * If the first argument is an array, then it will be treated as an array
     * of dependency string names to fetch. An optional function callback can
     * be specified to execute when all of those dependencies are available.
     *
     * Make a local req variable to help Caja compliance (it assumes things
     * on a require that are not standardized), and to give a short
     * name for minification/local scope use.
     */
    req = requirejs = function (deps, callback, errback, optional) {

        //Find the right context, use default
        var context, config,
            contextName = defContextName;

        // Determine if have config object in the call.
        if (!isArray(deps) && typeof deps !== 'string') {
            // deps is a config object
            config = deps;
            if (isArray(callback)) {
                // Adjust args if there are dependencies
                deps = callback;
                callback = errback;
                errback = optional;
            } else {
                deps = [];
            }
        }

        if (config && config.context) {
            contextName = config.context;
        }

        context = getOwn(contexts, contextName);
        if (!context) {
            context = contexts[contextName] = req.s.newContext(contextName);
        }

        if (config) {
            context.configure(config);
        }

        return context.require(deps, callback, errback);
    };

    /**
     * Support require.config() to make it easier to cooperate with other
     * AMD loaders on globally agreed names.
     */
    req.config = function (config) {
        return req(config);
    };

    /**
     * Execute something after the current tick
     * of the event loop. Override for other envs
     * that have a better solution than setTimeout.
     * @param  {Function} fn function to execute later.
     */
    req.nextTick = typeof setTimeout !== 'undefined' ? function (fn) {
        setTimeout(fn, 4);
    } : function (fn) { fn(); };

    /**
     * Export require as a global, but only if it does not already exist.
     */
    if (!require) {
        require = req;
    }

    req.version = version;

    //Used to filter out dependencies that are already paths.
    req.jsExtRegExp = /^\/|:|\?|\.js$/;
    req.isBrowser = isBrowser;
    s = req.s = {
        contexts: contexts,
        newContext: newContext
    };

    //Create default context.
    req({});

    //Exports some context-sensitive methods on global require.
    each([
        'toUrl',
        'undef',
        'defined',
        'specified'
    ], function (prop) {
        //Reference from contexts instead of early binding to default context,
        //so that during builds, the latest instance of the default context
        //with its config gets used.
        req[prop] = function () {
            var ctx = contexts[defContextName];
            return ctx.require[prop].apply(ctx, arguments);
        };
    });

    if (isBrowser) {
        head = s.head = document.getElementsByTagName('head')[0];
        //If BASE tag is in play, using appendChild is a problem for IE6.
        //When that browser dies, this can be removed. Details in this jQuery bug:
        //http://dev.jquery.com/ticket/2709
        baseElement = document.getElementsByTagName('base')[0];
        if (baseElement) {
            head = s.head = baseElement.parentNode;
        }
    }

    /**
     * Any errors that require explicitly generates will be passed to this
     * function. Intercept/override it if you want custom error handling.
     * @param {Error} err the error object.
     */
    req.onError = defaultOnError;

    /**
     * Creates the node for the load command. Only used in browser envs.
     */
    req.createNode = function (config, moduleName, url) {
        var node = config.xhtml ?
                document.createElementNS('http://www.w3.org/1999/xhtml', 'html:script') :
                document.createElement('script');
        node.type = config.scriptType || 'text/javascript';
        node.charset = 'utf-8';
        node.async = true;
        return node;
    };

    /**
     * Does the request to load a module for the browser case.
     * Make this a separate function to allow other environments
     * to override it.
     *
     * @param {Object} context the require context to find state.
     * @param {String} moduleName the name of the module.
     * @param {Object} url the URL to the module.
     */
    req.load = function (context, moduleName, url) {
        var config = (context && context.config) || {},
            node;
        if (isBrowser) {
            //In the browser so use a script tag
            node = req.createNode(config, moduleName, url);
            if (config.onNodeCreated) {
                config.onNodeCreated(node, config, moduleName, url);
            }

            node.setAttribute('data-requirecontext', context.contextName);
            node.setAttribute('data-requiremodule', moduleName);

            //Set up load listener. Test attachEvent first because IE9 has
            //a subtle issue in its addEventListener and script onload firings
            //that do not match the behavior of all other browsers with
            //addEventListener support, which fire the onload event for a
            //script right after the script execution. See:
            //https://connect.microsoft.com/IE/feedback/details/648057/script-onload-event-is-not-fired-immediately-after-script-execution
            //UNFORTUNATELY Opera implements attachEvent but does not follow the script
            //script execution mode.
            if (node.attachEvent &&
                    //Check if node.attachEvent is artificially added by custom script or
                    //natively supported by browser
                    //read https://github.com/jrburke/requirejs/issues/187
                    //if we can NOT find [native code] then it must NOT natively supported.
                    //in IE8, node.attachEvent does not have toString()
                    //Note the test for "[native code" with no closing brace, see:
                    //https://github.com/jrburke/requirejs/issues/273
                    !(node.attachEvent.toString && node.attachEvent.toString().indexOf('[native code') < 0) &&
                    !isOpera) {
                //Probably IE. IE (at least 6-8) do not fire
                //script onload right after executing the script, so
                //we cannot tie the anonymous define call to a name.
                //However, IE reports the script as being in 'interactive'
                //readyState at the time of the define call.
                useInteractive = true;

                node.attachEvent('onreadystatechange', context.onScriptLoad);
                //It would be great to add an error handler here to catch
                //404s in IE9+. However, onreadystatechange will fire before
                //the error handler, so that does not help. If addEventListener
                //is used, then IE will fire error before load, but we cannot
                //use that pathway given the connect.microsoft.com issue
                //mentioned above about not doing the 'script execute,
                //then fire the script load event listener before execute
                //next script' that other browsers do.
                //Best hope: IE10 fixes the issues,
                //and then destroys all installs of IE 6-9.
                //node.attachEvent('onerror', context.onScriptError);
            } else {
                node.addEventListener('load', context.onScriptLoad, false);
                node.addEventListener('error', context.onScriptError, false);
            }
            node.src = url;

            //For some cache cases in IE 6-8, the script executes before the end
            //of the appendChild execution, so to tie an anonymous define
            //call to the module name (which is stored on the node), hold on
            //to a reference to this node, but clear after the DOM insertion.
            currentlyAddingScript = node;
            if (baseElement) {
                head.insertBefore(node, baseElement);
            } else {
                head.appendChild(node);
            }
            currentlyAddingScript = null;

            return node;
        } else if (isWebWorker) {
            try {
                //In a web worker, use importScripts. This is not a very
                //efficient use of importScripts, importScripts will block until
                //its script is downloaded and evaluated. However, if web workers
                //are in play, the expectation is that a build has been done so
                //that only one script needs to be loaded anyway. This may need
                //to be reevaluated if other use cases become common.
                importScripts(url);

                //Account for anonymous modules
                context.completeLoad(moduleName);
            } catch (e) {
                context.onError(makeError('importscripts',
                                'importScripts failed for ' +
                                    moduleName + ' at ' + url,
                                e,
                                [moduleName]));
            }
        }
    };

    function getInteractiveScript() {
        if (interactiveScript && interactiveScript.readyState === 'interactive') {
            return interactiveScript;
        }

        eachReverse(scripts(), function (script) {
            if (script.readyState === 'interactive') {
                return (interactiveScript = script);
            }
        });
        return interactiveScript;
    }

    //Look for a data-main script attribute, which could also adjust the baseUrl.
    if (isBrowser && !cfg.skipDataMain) {
        //Figure out baseUrl. Get it from the script tag with require.js in it.
        eachReverse(scripts(), function (script) {
            //Set the 'head' where we can append children by
            //using the script's parent.
            if (!head) {
                head = script.parentNode;
            }

            //Look for a data-main attribute to set main script for the page
            //to load. If it is there, the path to data main becomes the
            //baseUrl, if it is not already set.
            dataMain = script.getAttribute('data-main');
            if (dataMain) {
                //Preserve dataMain in case it is a path (i.e. contains '?')
                mainScript = dataMain;

                //Set final baseUrl if there is not already an explicit one.
                if (!cfg.baseUrl) {
                    //Pull off the directory of data-main for use as the
                    //baseUrl.
                    src = mainScript.split('/');
                    mainScript = src.pop();
                    subPath = src.length ? src.join('/')  + '/' : './';

                    cfg.baseUrl = subPath;
                }

                //Strip off any trailing .js since mainScript is now
                //like a module name.
                mainScript = mainScript.replace(jsSuffixRegExp, '');

                //If mainScript is still a path, fall back to dataMain
                if (req.jsExtRegExp.test(mainScript)) {
                    mainScript = dataMain;
                }

                //Put the data-main script in the files to load.
                cfg.deps = cfg.deps ? cfg.deps.concat(mainScript) : [mainScript];

                return true;
            }
        });
    }

    /**
     * The function that handles definitions of modules. Differs from
     * require() in that a string for the module should be the first argument,
     * and the function to execute after dependencies are loaded should
     * return a value to define the module corresponding to the first argument's
     * name.
     */
    define = function (name, deps, callback) {
        var node, context;

        //Allow for anonymous modules
        if (typeof name !== 'string') {
            //Adjust args appropriately
            callback = deps;
            deps = name;
            name = null;
        }

        //This module may not have dependencies
        if (!isArray(deps)) {
            callback = deps;
            deps = null;
        }

        //If no name, and callback is a function, then figure out if it a
        //CommonJS thing with dependencies.
        if (!deps && isFunction(callback)) {
            deps = [];
            //Remove comments from the callback string,
            //look for require calls, and pull them into the dependencies,
            //but only if there are function args.
            if (callback.length) {
                callback
                    .toString()
                    .replace(commentRegExp, '')
                    .replace(cjsRequireRegExp, function (match, dep) {
                        deps.push(dep);
                    });

                //May be a CommonJS thing even without require calls, but still
                //could use exports, and module. Avoid doing exports and module
                //work though if it just needs require.
                //REQUIRES the function to expect the CommonJS variables in the
                //order listed below.
                deps = (callback.length === 1 ? ['require'] : ['require', 'exports', 'module']).concat(deps);
            }
        }

        //If in IE 6-8 and hit an anonymous define() call, do the interactive
        //work.
        if (useInteractive) {
            node = currentlyAddingScript || getInteractiveScript();
            if (node) {
                if (!name) {
                    name = node.getAttribute('data-requiremodule');
                }
                context = contexts[node.getAttribute('data-requirecontext')];
            }
        }

        //Always save off evaluating the def call until the script onload handler.
        //This allows multiple modules to be in a file without prematurely
        //tracing dependencies, and allows for anonymous module support,
        //where the module name is not known until the script onload event
        //occurs. If no context, use the global queue, and get it processed
        //in the onscript load callback.
        if (context) {
            context.defQueue.push([name, deps, callback]);
            context.defQueueMap[name] = true;
        } else {
            globalDefQueue.push([name, deps, callback]);
        }
    };

    define.amd = {
        jQuery: true
    };

    /**
     * Executes the text. Normally just uses eval, but can be modified
     * to use a better, environment-specific call. Only used for transpiling
     * loader plugins, not for plain JS modules.
     * @param {String} text the text to execute/evaluate.
     */
    req.exec = function (text) {
        /*jslint evil: true */
        return eval(text);
    };

    //Set up with config info.
    req(cfg);
}(this));
",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "T44iwKR7HFJe",
    "outputId": "c30ea8fb-36e5-43eb-e6f1-e5ce007bb40d",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.path_data = {\"graph\": {\"directed\": false, \"multigraph\": false, \"graph\": {}, \"nodes\": [{\"keyword\": [\"plant\", \"plants\"], \"count\": 3, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": 0.1887, \"y\": 0.1382, \"id\": 675}, {\"keyword\": [\"homology\"], \"count\": 0, \"trace_color\": \"#7570b3\", \"trace\": \"link\", \"x\": 0.0425, \"y\": -0.2233, \"id\": 260}, {\"keyword\": [\"sets\", \"set\"], \"count\": 35, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": -0.1973, \"y\": 0.3342, \"id\": 548}, {\"keyword\": [\"voxelization\", \"voxels\", \"voxel\"], \"count\": 5, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": 0.3867, \"y\": -0.1232, \"id\": 518}, {\"keyword\": [\"separating\"], \"count\": 0, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": 0.3637, \"y\": 0.9311, \"id\": 936}, {\"keyword\": [\"level\", \"levels\"], \"count\": 31, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": -0.2456, \"y\": 0.8893, \"id\": 536}, {\"keyword\": [\"spine\"], \"count\": 2, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": -0.7758, \"y\": -0.8543, \"id\": 1833}, {\"keyword\": [\"arc\"], \"count\": 2, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": 0.8065, \"y\": 0.2271, \"id\": 1099}, {\"keyword\": [\"approximation\", \"approximations\"], \"count\": 0, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": -0.687, \"y\": 0.0099, \"id\": 590}, {\"keyword\": [\"betti\"], \"count\": 1, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": 0.0649, \"y\": 0.5834, \"id\": 1072}, {\"keyword\": [\"numbers\"], \"count\": 0, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": -0.4406, \"y\": 0.5623, \"id\": 1073}, {\"keyword\": [\"shakespeare\"], \"count\": 0, \"trace_color\": \"#d95f02\", \"trace\": \"query\", \"x\": 0.0694, \"y\": -1.0, \"id\": 21}, {\"keyword\": [\"cliques\"], \"count\": 0, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": -0.2996, \"y\": -0.6848, \"id\": 2166}, {\"keyword\": [\"arrays\"], \"count\": 0, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": -0.2725, \"y\": -0.1159, \"id\": 1783}, {\"keyword\": [\"oct-trees\"], \"count\": 0, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": -0.0469, \"y\": 0.0298, \"id\": 1784}, {\"keyword\": [\"reeb\"], \"count\": 2, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": 0.1504, \"y\": -0.5278, \"id\": 1692}, {\"keyword\": [\"bard\"], \"count\": 1, \"trace_color\": \"#1b9e77\", \"trace\": \"target\", \"x\": 0.8925, \"y\": -0.1761, \"id\": 1208}], \"links\": [{\"weight\": 0.029175557259215834, \"sim\": 0.9708244427407842, \"source\": 675, \"target\": 1784}, {\"weight\": 0.18752145906341777, \"sim\": 0.8124785409365822, \"source\": 675, \"target\": 548}, {\"weight\": 0.3260455365690378, \"sim\": 0.6739544634309622, \"source\": 675, \"target\": 590}, {\"weight\": 0.45733979620874987, \"sim\": 0.5426602037912501, \"source\": 675, \"target\": 1099}, {\"weight\": 0.04231782645444282, \"sim\": 0.9576821735455572, \"source\": 260, \"target\": 1784}, {\"weight\": 0.20409554645833905, \"sim\": 0.795904453541661, \"source\": 260, \"target\": 1692}, {\"weight\": 0.13000880246321378, \"sim\": 0.8699911975367862, \"source\": 548, \"target\": 1072}, {\"weight\": 0.12976146223035834, \"sim\": 0.8702385377696417, \"source\": 518, \"target\": 1784}, {\"weight\": 0.32671208854342726, \"sim\": 0.6732879114565727, \"source\": 936, \"target\": 1072}, {\"weight\": 0.1970507607044607, \"sim\": 0.8029492392955393, \"source\": 536, \"target\": 1072}, {\"weight\": 0.3603186052130585, \"sim\": 0.6396813947869415, \"source\": 1833, \"target\": 2166}, {\"weight\": 0.05820060631031243, \"sim\": 0.9417993936896876, \"source\": 1099, \"target\": 1208}, {\"weight\": 0.0745262361785366, \"sim\": 0.9254737638214634, \"source\": 1072, \"target\": 1073}, {\"weight\": 0.177321602924832, \"sim\": 0.822678397075168, \"source\": 21, \"target\": 2166}, {\"weight\": 0.20065894786657434, \"sim\": 0.7993410521334257, \"source\": 2166, \"target\": 1692}, {\"weight\": 0.05103583675790602, \"sim\": 0.948964163242094, \"source\": 1783, \"target\": 1784}]}, \"docs\": {\"21+260\": {\"cx\": 0.05593153648576874, \"cy\": -0.6116481577541971, \"count\": 1, \"docs\": [{\"title\": \"'Shall I compare thee to a network?': Visualizing the Topological Structure of Shakespeare\\u2019s Plays\", \"keywords\": [\"visualization\", \"shakespeare\", \"social network analysis\", \"topology\", \"persistent homology\"], \"trace\": \"query\", \"tokens\": [\"shakespear\", \"homolog\"], \"token_indices\": [23, 341], \"token_indices_c\": [21, 260]}]}, \"21\": {\"cx\": 0.06941222683644287, \"cy\": -1.0, \"count\": 2, \"docs\": [{\"title\": \"Person\\u00e6: A Character- Visualisation Tool for Dramatic Texts\", \"keywords\": [\"visualization\", \"networks\", \"drama\", \"exploratory\", \"shakespeare\"], \"trace\": \"query\", \"tokens\": [\"shakespear\"], \"token_indices\": [23], \"token_indices_c\": [21]}, {\"title\": \"Analyzing Social Networks of XML Plays: Exploring Shakespeare\\u2019s Genres\", \"keywords\": [\"social networks\", \"shakespeare\", \"genre\", \"drama\", \"xml\"], \"trace\": \"query\", \"tokens\": [\"shakespear\"], \"token_indices\": [23], \"token_indices_c\": [21]}]}, \"518\": {\"cx\": 0.3866705387669331, \"cy\": -0.12318084318290119, \"count\": 3, \"docs\": [{\"title\": \"Volume sampled voxelization of geometric primitives\", \"keywords\": [\"voxelization\", \"volume sampling\", \"discrete ray tracing\", \"filtering\"], \"trace\": \"target\", \"tokens\": [\"voxel\"], \"token_indices\": [602], \"token_indices_c\": [518]}, {\"title\": \"Mixing translucent polygons with volumes\", \"keywords\": [\"mixing polygons and volumes\", \"translucent polygon rendering\", \"volume rendering\", \"ray casting\", \"voxelization\"], \"trace\": \"target\", \"tokens\": [\"voxel\"], \"token_indices\": [602], \"token_indices_c\": [518]}, {\"title\": \"3D digital cleansing using segmentation rays\", \"keywords\": [\"volume segmentation\", \"segmentation rays\", \"partial volume voxels\", \"volume rendering\", \"virtual endoscopy\", \"virtual colonoscopy\"], \"trace\": \"target\", \"tokens\": [\"voxel\"], \"token_indices\": [602], \"token_indices_c\": [518]}]}, \"536\": {\"cx\": -0.24562770163725492, \"cy\": 0.8892982207355894, \"count\": 19, \"docs\": [{\"title\": \"Automated generation of visual simulation databases using remote sensing and GIS\", \"keywords\": [\"remote sensing\", \"geographic information systems\", \"geographic databases\", \"satellite images\", \"classification\", \"visual simulation\", \"level of detail\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Multiresolution tetrahedral framework for visualizing regular volume data\", \"keywords\": [\"volume visualization\", \"multiresolution volume\", \"level of detail\", \"isosurface extraction\", \"volume subdivision\", \"polygon simplification\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Simplifying surfaces with color and texture using quadric error metrics\", \"keywords\": [\"surface simplification\", \"multiresolution modeling\", \"level of detail\", \"quadric error metric\", \"edge contraction\", \"surface properties\", \"discontinuity preservation\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"LOD-sprite technique for accelerated terrain rendering\", \"keywords\": [\"image-based modeling and rendering\", \"texture mapping\", \"acceleration techniques\", \"multi-resolution\", \"level of detail\", \"terrain rendering\", \"virtual reality\", \"virtual environments\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"New quadric metric for simplifying meshes with appearance attributes\", \"keywords\": [\"level of detail\", \"mesh decimation\", \"multiresolution\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Time-critical Multiresolution Scene Rendering\", \"keywords\": [\"multiresolution modeling\", \"level of detail\", \"adaptive rendering\", \"time-critical graphics\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Texturing techniques for terrain visualization\", \"keywords\": [\"terrain rendering\", \"texture mapping\", \"multiresolution\", \"level of detail\", \"3d maps\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"POP: A Hybrid Point and Polygon Rendering System for Large Data\", \"keywords\": [\"rendering system\", \"spatial data structures\", \"level of detail algorithms\", \"hybrid rendering systems\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Interactive rendering of large volume data sets\", \"keywords\": [\"compression algorithms\", \"level of detail algorithms\", \"scientific visualization\", \"volume rendering\", \"wavelets\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Process visualization with levels of detail\", \"keywords\": [\"process visualization\", \"information visualization\", \"levels of detail\", \"focus+context visualization\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"PMR: point to mesh rendering, a feature-based approach\", \"keywords\": [\"rendering\", \"feature\", \"multi-resolution\", \"level of details\", \"voronoi diagram\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Optimized view-dependent rendering for large polygonal datasets\", \"keywords\": [\"surface simplification\", \"level of detail\", \"multiresolution hierarchies\", \"view-dependent rendering\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Fast view-dependent level-of-detail rendering using cached geometry\", \"keywords\": [\"view-dependent mesh\", \"level of detail\", \"height fields\", \"terrain\", \"binary triangle trees\", \"triangle bintree\", \"multiresolution meshes\", \"displacement maps\", \"frame-to-frame coherence\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Appearance-preserving view-dependent visualization\", \"keywords\": [\"view-dependent\", \"level of detail\", \"mesh simplification\", \"appearance-preserving\", \"multiresolution models\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Real-time refinement and simplification of adaptive triangular meshes\", \"keywords\": [\"adaptive meshes\", \"refinement and simplification\", \"subdivision\", \"multiresoluton\", \"level of detail\", \"frame-to-frame coherence\", \"out-of-core visualization\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Interactive view-dependent rendering with conservative occlusion culling in complex environments\", \"keywords\": [\"interactive display\", \"view-dependent rendering\", \"occlusion culling\", \"level of detail\", \"multiresolution hierarchies\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"Interpolation and visualization for advected scalar fields\", \"keywords\": [\"doppler radar\", \"volume rendering\", \"optical flow\", \"level of details\", \"vector field visualization\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"A Visual Analysis Concept for the Validation of Geoscientific Simulation Models\", \"keywords\": [\"earth science visualization\", \"model validation\", \"coordinated multiple views\", \"spatio-temporal visualization\", \"sea level indicators\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}, {\"title\": \"An Information-Theoretic Approach to the Cost-benefit Analysis of Visualization in Virtual Environments\", \"keywords\": [\"theory of visualization\", \"virtual environments\", \"four levels of visualization\", \"virtual reality\", \"augmented reality\", \"mixed reality\", \"cost-benefit analysis\", \"information theory\", \"cognitive sciences\", \"visualization applications\", \"immersive analytics\"], \"trace\": \"target\", \"tokens\": [\"level\"], \"token_indices\": [620], \"token_indices_c\": [536]}]}, \"548\": {\"cx\": -0.19726127910576816, \"cy\": 0.3341668468494314, \"count\": 23, \"docs\": [{\"title\": \"Recursive pattern: a technique for visualizing very large amounts of data\", \"keywords\": [\"visualizing large data sets\", \"visualizing multidimensional and multivariate data\", \"visualizing large sequential data sets\", \"recursive visualization techniques\", \"interfaces to databases\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"The Gridfit algorithm: an efficient and effective approach to visualizing large amounts of spatial data\", \"keywords\": [\"visualizing large data sets\", \"visualizing spatially referenced data\", \"visualizing geographical data\", \"interfaces to databases\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Visualizing massive multi-digraphs\", \"keywords\": [\"visualization\", \"massive data sets\", \"graphs\", \"hierarchies\", \"out-of-core algorithms\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Graph sketches\", \"keywords\": [\"visualization\", \"massive data sets\", \"graphs\", \"hierarchies\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"A graphics hardware-based vortex detection and visualization system\", \"keywords\": [\"features in volume data sets\", \"flow visualization\", \"hardware acceleration\", \"3d vector field visualization\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Adaptive 4-8 texture hierarchies\", \"keywords\": [\"large data set visualization\", \"level-of-detail techniques\", \"view-dependent visualization\", \"adaptive textures\", \"out-of-core algorithms\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Efficient point-based isosurface exploration using the span-triangle\", \"keywords\": [\"point-based visualization\", \"isosurfaces\", \"hardware acceleration\", \"large data set visualization\", \"visualization in medicine\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"A contract based system for large data visualization\", \"keywords\": [\"large data set visualization\", \"data flow networks\", \"contract-based system\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"An interactive 3D integration of parallel coordinates and star glyphs\", \"keywords\": [\"parallel glyphs\", \"parallel coordinates\", \"star glyphs\", \"multi-dimensional data sets\", \"3d visualization\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Visualization and Analysis of Large Data Collections: a Case Study Applied to Confocal Microscopy Data\", \"keywords\": [\"biomedical visualization\", \"features in volume data sets\", \"large data set visualization\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Scalable Data Servers for Large Multivariate Volume Visualization\", \"keywords\": [\"parallel and distributed volume visualization\", \"large data set visualization\", \"multi-variate visualization\", \"volume visualization\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Geovisual analytics for self-organizing network data\", \"keywords\": [\"geovisual analytics\", \"visualization\", \"self-organizing network\", \"multi-layer\", \"multi-dimensional\", \"time-varying\", \"geospatial data sets\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Untangling Euler Diagrams\", \"keywords\": [\"information visualization\", \"euler diagrams\", \"set visualization\", \"graph visualization\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Design Study of LineSets, a Novel Set Visualization Technique\", \"keywords\": [\"set visualization\", \"clustering\", \"faceted data visualization\", \"graph visualization\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"VAICo: Visual Analysis for Image Comparison\", \"keywords\": [\"comparative visualization\", \"focus+context visualization\", \"image set comparison\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Common Angle Plots as Perception-True Visualizations of Categorical Associations\", \"keywords\": [\"linewidth illusion\", \"data visualization\", \"high-dimensional displays\", \"parallel sets\", \"hammock plots\", \"muller-lyer illusion\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Radial Sets: Interactive Visual Analysis of Large Overlapping Sets\", \"keywords\": [\"multi-valued attributes\", \"set-typed data\", \"overlapping sets\", \"visualization technique\", \"scalability\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Decomposition and Simplification of Multivariate Data using Pareto Sets\", \"keywords\": [\"multivariate topology\", \"pareto set\", \"simplification\", \"decomposition\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"OnSet: A Visualization Technique for Large-scale Binary Set Data\", \"keywords\": [\"set visualization\", \"information visualization\", \"direct manipulation\", \"euler diagrams\", \"interaction\", \"logical operations\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"UpSet: Visualization of Intersecting Sets\", \"keywords\": [\"sets\", \"set visualization\", \"sets intersections\", \"set attributes\", \"set relationships\", \"multidimensional data\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations\", \"keywords\": [\"multi-valued attributes\", \"sets\", \"visualization\", \"set visualization\", \"data exploration\", \"interaction\", \"design\", \"scalability\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"PowerSet: A Comprehensive Visualization of Set Intersections\", \"keywords\": [\"scalability\", \"set visualization\", \"treemaps\", \"interaction\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}, {\"title\": \"Formalizing Visualization Design Knowledge as Constraints: Actionable and Extensible Models in Draco\", \"keywords\": [\"automated visualization design\", \"perceptual effectiveness\", \"constraints\", \"knowledge bases\", \"answer set programming\"], \"trace\": \"target\", \"tokens\": [\"set\"], \"token_indices\": [632], \"token_indices_c\": [548]}]}, \"590\": {\"cx\": -0.6870478172193779, \"cy\": 0.009904056427714424, \"count\": 13, \"docs\": [{\"title\": \"Mesh reduction with error control\", \"keywords\": [\"hierarchical approximation\", \"model simplification\", \"levels-of-detail generation\", \"shape approximation\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Smooth hierarchical surface triangulations\", \"keywords\": [\"mesh simplification\", \"triangle meshes\", \"level-of-detail representation\", \"shape approximation\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Simplifying polygonal models using successive mappings\", \"keywords\": [\"model simplification\", \"levels-of-detail\", \"surface approximation\", \"projection\", \"linear programming\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Simplification of tetrahedral meshes\", \"keywords\": [\"approximation\", \"hierarchical representation\", \"mesh generation\", \"multiresolution method\", \"scattered data\", \"spline\", \"triangulation\", \"visualization\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Efficient co-triangulation of large data sets\", \"keywords\": [\"delaunay triangulation\", \"scattered data\", \"multidimensional approximation\", \"higher-dimensional approximation\", \"computational geometry\", \"data-structures\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"A unified approach for simplifying polygonal and spline models\", \"keywords\": [\"model simplification\", \"levels-of-detail\", \"surface approximation\", \"spline patches\", \"surface fitting\", \"dynamic tessellation\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Topology preserving and controlled topology simplifying multiresolution isosurface extraction\", \"keywords\": [\"tetrahedral grid refinement\", \"implicit surface approximation\", \"level-of-detail\", \"topological genus\", \"critical points\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Fitting Subdivision Surfaces\", \"keywords\": [\"animation\", \"cad\", \"curves and surfaces\", \"geometric modeling\", \"digital geometry processing\", \"subdivision schemes\", \"approximation\", \"quasi-interpolation\", \"catmull-clark\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Smooth approximation and rendering of large scattered data sets\", \"keywords\": [\"scattered data approximation\", \"least squares approximation\", \"terrain visualization\", \"data compression\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Approximating normals for marching cubes applied to locally supported isosurfaces\", \"keywords\": [\"isosurface\", \"normal vectors\", \"marching cubes\", \"triangular mesh\", \"topology\", \"gouraud shading\", \"approximation\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Gradient Estimation Revitalized\", \"keywords\": [\"derivative\", \"gradient\", \"reconstruction\", \"sampling\", \"lattice\", \"interpolation\", \"approximation\", \"frequency error kernel\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Vessel Visualization using Curved Surface Reformation\", \"keywords\": [\"reformation\", \"volume rendering\", \"surface approximation\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}, {\"title\": \"Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering\", \"keywords\": [\"multi-resolution representations\", \"sparse approximation\", \"pursuit algorithms\", \"large-scale volume rendering\"], \"trace\": \"target\", \"tokens\": [\"approxim\"], \"token_indices\": [676], \"token_indices_c\": [590]}]}, \"675\": {\"cx\": 0.18872331555848845, \"cy\": 0.1382493203453507, \"count\": 2, \"docs\": [{\"title\": \"Visualization of plant growth\", \"keywords\": [\"shape representation\", \"image sequence analysis\", \"non-rigid motion\", \"plant biology\"], \"trace\": \"target\", \"tokens\": [\"plant\"], \"token_indices\": [763], \"token_indices_c\": [675]}, {\"title\": \"Interactive visualization of complex plant ecosystems\", \"keywords\": [\"synthetic plants\", \"ecosystems\", \"point-based rendering\", \"level-of-detail algorithms\"], \"trace\": \"target\", \"tokens\": [\"plant\"], \"token_indices\": [763], \"token_indices_c\": [675]}]}, \"536+548\": {\"cx\": -0.22144449037151154, \"cy\": 0.6117325337925104, \"count\": 9, \"docs\": [{\"title\": \"Semi-regular mesh extraction from volumes\", \"keywords\": [\"semi-regular meshes\", \"subdivision\", \"volumes\", \"surface extraction\", \"implicit functions\", \"level set methods\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}, {\"title\": \"Wavelet representation of contour sets\", \"keywords\": [\"contours\", \"geometry compression\", \"iso-surfaces\", \"level sets\", \"multiresolution methods\", \"wavelets\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}, {\"title\": \"Geometric surface smoothing via anisotropic diffusion of normals\", \"keywords\": [\"anisotropic diffusion\", \"surface fairing\", \"geometric surface processing\", \"intrinsic laplacian of curvature\", \"level sets\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}, {\"title\": \"Level set segmentation from multiple non-uniform volume datasets\", \"keywords\": [\"segmentation\", \"visualization\", \"level set models\", \"3d reconstruction\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}, {\"title\": \"Interactive deformation and visualization of level set surfaces using graphics hardware\", \"keywords\": [\"deformable models\", \"image segmentation\", \"volume visualization\", \"gpu\", \"level sets\", \"streaming computation\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}, {\"title\": \"Rough interface reconstruction using the level set method\", \"keywords\": [\"point sampled data\", \"surface reconstruction\", \"level set method\", \"shock filter\", \"total variation preserving\", \"rough surface\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}, {\"title\": \"Surface reconstruction via contour metamorphosis: an Eulerian approach with Lagrangian particle tracking\", \"keywords\": [\"3d reconstruction\", \"contours\", \"level sets\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}, {\"title\": \"Smooth Surface Extraction from Unstructured Point-based Volume Data Using PDEs\", \"keywords\": [\"pdes\", \"surface extraction\", \"level sets\", \"point-based visualization\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}, {\"title\": \"Decoupling Illumination from Isosurface Generation Using 4D Light Transport\", \"keywords\": [\"physically-based illumination\", \"isosurface\", \"level set\", \"light transport\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\"], \"token_indices\": [620, 632], \"token_indices_c\": [536, 548]}]}, \"936\": {\"cx\": 0.3637417306417835, \"cy\": 0.9311459503624765, \"count\": 2, \"docs\": [{\"title\": \"Scanline surfacing: building separating surfaces from planar contours\", \"keywords\": [\"separating surfaces\", \"planar contours\", \"surface construction\", \"scanline\"], \"trace\": \"target\", \"tokens\": [\"separ\"], \"token_indices\": [1050], \"token_indices_c\": [936]}, {\"title\": \"Topological structures of 3D tensor fields\", \"keywords\": [\"separating surface\", \"trisectors\", \"wedges\", \"symmetric tensors\", \"hyperstreamlines\", \"degenerate tensors\", \"tensor topology\", \"topological line\"], \"trace\": \"target\", \"tokens\": [\"separ\"], \"token_indices\": [1050], \"token_indices_c\": [936]}]}, \"536+548+1072+1073\": {\"cx\": -0.20466422008120908, \"cy\": 0.5922690132328924, \"count\": 1, \"docs\": [{\"title\": \"Efficient computation of the topology of level sets\", \"keywords\": [\"isosurfaces\", \"level set topology\", \"betti numbers\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\", \"betti\", \"number\"], \"token_indices\": [620, 632, 1215, 1216], \"token_indices_c\": [536, 548, 1072, 1073]}]}, \"1099\": {\"cx\": 0.8064903248966169, \"cy\": 0.22710502087766274, \"count\": 1, \"docs\": [{\"title\": \"Arc diagrams: visualizing structure in strings\", \"keywords\": [\"string\", \"sequence\", \"visualization\", \"arc diagram\", \"music\", \"text\", \"code\"], \"trace\": \"target\", \"tokens\": [\"arc\"], \"token_indices\": [1246], \"token_indices_c\": [1099]}]}, \"518+590\": {\"cx\": -0.15018863922622241, \"cy\": -0.05663839337759338, \"count\": 1, \"docs\": [{\"title\": \"Quasi-static approach approximation for 6 degrees-of-freedom haptic rendering\", \"keywords\": [\"6-dof haptics\", \"physically based modeling\", \"voxel sampling\", \"quasi-static approximation\", \"virtual coupling\"], \"trace\": \"target\", \"tokens\": [\"voxel\", \"approxim\"], \"token_indices\": [602, 676], \"token_indices_c\": [518, 590]}]}, \"536+548+936\": {\"cx\": -0.02638241670041319, \"cy\": 0.7182036726491657, \"count\": 1, \"docs\": [{\"title\": \"Counting cases in marching cubes: toward a generic algorithm for producing substitopes\", \"keywords\": [\"level set\", \"isosurface\", \"orbit\", \"group action\", \"marching cubes\", \"separating surfaces\", \"geometric substitution\", \"substitope\"], \"trace\": \"target\", \"tokens\": [\"level\", \"set\", \"separ\"], \"token_indices\": [620, 632, 1050], \"token_indices_c\": [536, 548, 936]}]}, \"1099+1208\": {\"cx\": 0.8495127012415364, \"cy\": 0.02552040512819577, \"count\": 1, \"docs\": [{\"title\": \"BARD: A visualization tool for biological sequence analysis\", \"keywords\": [\"sequence analysis\", \"comparative genomics\", \"visualization\", \"arc diagram\", \"bard\"], \"trace\": \"target\", \"tokens\": [\"arc\", \"bard\"], \"token_indices\": [1246, 1383], \"token_indices_c\": [1099, 1208]}]}, \"1692\": {\"cx\": 0.15036977446638866, \"cy\": -0.5277930086238893, \"count\": 1, \"docs\": [{\"title\": \"Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees\", \"keywords\": [\"reeb graph\", \"scalar field topology\", \"isosurfaces\", \"topological simplification\"], \"trace\": \"target\", \"tokens\": [\"reeb\"], \"token_indices\": [1977], \"token_indices_c\": [1692]}]}, \"1073\": {\"cx\": -0.440619476864261, \"cy\": 0.5622532930345789, \"count\": 1, \"docs\": [{\"title\": \"An Extension of Wilkinson's Algorithm for Positioning Tick Labels on Axes\", \"keywords\": [\"axis labeling\", \"nice numbers\"], \"trace\": \"target\", \"tokens\": [\"number\"], \"token_indices\": [1216], \"token_indices_c\": [1073]}]}, \"260+518+536+548+590+675+1783+1784\": {\"cx\": -0.12588853348865126, \"cy\": 0.13818127961800206, \"count\": 1, \"docs\": [{\"title\": \"Computing Robustness and Persistence for Images\", \"keywords\": [\"voxel arrays\", \"oct-trees\", \"persistent homology\", \"persistence diagrams\", \"level sets\", \"robustness\", \"approximations\", \"plant roots\"], \"trace\": \"target\", \"tokens\": [\"homolog\", \"voxel\", \"level\", \"set\", \"approxim\", \"plant\", \"array\", \"oct-tre\"], \"token_indices\": [341, 602, 620, 632, 676, 763, 2105, 2106], \"token_indices_c\": [260, 518, 536, 548, 590, 675, 1783, 1784]}]}, \"1833\": {\"cx\": -0.7758092391508855, \"cy\": -0.8543245932455197, \"count\": 2, \"docs\": [{\"title\": \"Topological Spines: A Structure-preserving Visual Representation of Scalar fields\", \"keywords\": [\"scalar field topology\", \"topological spine\", \"extremum graph\", \"morse-smale complex\"], \"trace\": \"target\", \"tokens\": [\"spine\"], \"token_indices\": [2169], \"token_indices_c\": [1833]}, {\"title\": \"Interactive Visual Analysis of Image-Centric Cohort Study Data\", \"keywords\": [\"interactive visual analysis\", \"epidemiology\", \"spine\"], \"trace\": \"target\", \"tokens\": [\"spine\"], \"token_indices\": [2169], \"token_indices_c\": [1833]}]}, \"260+1692\": {\"cx\": 0.09641031030074164, \"cy\": -0.3755446620661418, \"count\": 1, \"docs\": [{\"title\": \"Augmented Topological Descriptors of Pore Networks for Material Science\", \"keywords\": [\"reeb graph\", \"persistent homology\", \"topological data analysis\", \"geometric algorithms\", \"segmentation\", \"microscopy\"], \"trace\": \"target\", \"tokens\": [\"homolog\", \"reeb\"], \"token_indices\": [341, 1977], \"token_indices_c\": [260, 1692]}]}, \"1783\": {\"cx\": -0.27245144385469566, \"cy\": -0.11585599458151945, \"count\": 1, \"docs\": [{\"title\": \"Fixed-Rate Compressed Floating-Point Arrays\", \"keywords\": [\"data compression\", \"floating-point arrays\", \"orthogonal block transform\", \"embedded coding\"], \"trace\": \"target\", \"tokens\": [\"array\"], \"token_indices\": [2105], \"token_indices_c\": [1783]}]}, \"260+2166\": {\"cx\": -0.12855921590204433, \"cy\": -0.4540337285493561, \"count\": 1, \"docs\": [{\"title\": \"Clique Community Persistence: A Topological Visual Analysis Approach for Complex Networks\", \"keywords\": [\"persistent homology\", \"topological persistence\", \"cliques\", \"complex networks\", \"visual analysis\"], \"trace\": \"target\", \"tokens\": [\"homolog\", \"cliqu\"], \"token_indices\": [341, 2602], \"token_indices_c\": [260, 2166]}]}}}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "         <div id='vis'></div>\n",
       "         <style>\n",
       "           .container { width:100% !important; }\n",
       "           .vis-tooltip {\n",
       "              position: absolute;\n",
       "              z-index: 10;\n",
       "              visibility: hidden;\n",
       "              background-color: whitesmoke;\n",
       "              text-align: center;\n",
       "              padding: 4px;\n",
       "              border-radius: 4px;\n",
       "              font-weight: bold;\n",
       "              color: black;\n",
       "              pointer-events: none;\n",
       "          }\n",
       "         </style>\n",
       "         <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "         <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              \"d3\": \"https://d3js.org/d3.v5.min\",\n",
       "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        <script>\n",
       "          \n",
       "          requirejs(['d3'], function(d3) {\n",
       "            const width = 1850,\n",
       "                  height = 1850;\n",
       "                  \n",
       "\n",
       "            const svg = d3.select('#vis').append('svg')\n",
       "                            .attr('id', 'vis-svg')\n",
       "                            .attr('width', width)\n",
       "                            .attr('height', height);\n",
       "            graph_json = window.path_data\n",
       "            \n",
       "            console.log(JSON.stringify(graph_json))\n",
       "            \n",
       "            const graph = graph_json['graph'];\n",
       "            const docs = graph_json['docs'];\n",
       "\n",
       "            const xScale = d3.scaleLinear().domain(d3.extent(graph.nodes, d=>d.x)).range([160, width-160])\n",
       "            const yScale = d3.scaleLinear().domain(d3.extent(graph.nodes, d=>d.y)).range([40, height-40])\n",
       "\n",
       "            const linkline = d3.line()\n",
       "                                  .x(d => xScale(d.x))\n",
       "                                  .y(d => yScale(d.y));\n",
       "\n",
       "            const docs_three = Object.keys(docs).filter(d=>d.split('+').length >= 2).map(d => docs[d])\n",
       "\n",
       "            const doc_lines_data = []\n",
       "            \n",
       "            const tooltip = d3.select(\"#vis\")\n",
       "                      .append(\"div\")\n",
       "                      .attr('class', 'vis-tooltip');\n",
       "\n",
       "            docs_three.forEach(doc => {\n",
       "              doc['docs'].forEach(d => {\n",
       "                d['token_indices_c'].forEach(t=> {\n",
       "                  const target_node = graph.nodes.filter(r => r.id == t)[0]\n",
       "                  const line_points = [\n",
       "                    {\n",
       "                      'x' : doc.cx,\n",
       "                      'y' : doc.cy \n",
       "                    },\n",
       "                    {\n",
       "                      'x' : target_node.x,\n",
       "                      'y' : target_node.y\n",
       "                    }\n",
       "                  ]\n",
       "                  doc_lines_data.push(line_points)\n",
       "                })\n",
       "              })\n",
       "            })\n",
       "\n",
       "\n",
       "            const doc_links = svg.append(\"g\")\n",
       "                            .attr(\"id\", \"doc_links\")\n",
       "                          .selectAll(\"line\")\n",
       "                          .data(doc_lines_data)\n",
       "                          .enter().append(\"path\")\n",
       "                            .attr(\"stroke-dasharray\", '5,5')\n",
       "                            .style(\"stroke\", \"black\")\n",
       "                            .attr(\"stroke-width\", 0.5)\n",
       "                            .attr(\"opacity\", 0.4)\n",
       "                            .attr(\"d\", d => linkline(d));\n",
       "\n",
       "\n",
       "            const links = svg.append(\"g\")\n",
       "                            .attr(\"id\", \"links\")\n",
       "                          .selectAll(\"line\")\n",
       "                          .data(graph.links)\n",
       "                          .enter().append(\"path\")\n",
       "                            .style(\"stroke\", \"black\")\n",
       "                            .attr(\"stroke-width\", 0.5)\n",
       "                            .attr(\"opacity\", 0.4)\n",
       "                            .attr(\"d\", d => linkline(graph.nodes.filter(b=>b.id == d.source || b.id == d.target)));\n",
       "\n",
       "\n",
       "            function getBB(selection) {\n",
       "                selection.each(function(d){d.bbox = this.getBBox();})\n",
       "            }\n",
       "\n",
       "            const nodes_g = svg.append(\"g\")\n",
       "                            .attr(\"id\", \"nodes\")\n",
       "                          .selectAll('g')\n",
       "                          .data(graph.nodes)\n",
       "                          .enter()\n",
       "                          .append('g');\n",
       "            nodes_g\n",
       "                  .append('text')\n",
       "                    .attr(\"class\", \"node\")\n",
       "                    .text(d=> d.keyword[0])\n",
       "                    .attr('x', d => xScale(d.x))\n",
       "                    .attr('y', d =>  yScale(d.y))\n",
       "                    .style('fill', d=>d.trace_color)\n",
       "                    .style('font-size', \"10px\")\n",
       "                    .style('font-weight', \"bold\")\n",
       "                    .style('text-anchor', \"middle\")\n",
       "                    .call(getBB);\n",
       "\n",
       "            nodes_g.insert(\"rect\", \"text\")\n",
       "                              .attr('x', d => xScale(d.x) - d.bbox.width/2)\n",
       "                              .attr('y', d => yScale(d.y) - 3*(d.bbox.height/4))\n",
       "                              .attr(\"width\", function(d){return d.bbox.width})\n",
       "                              .attr(\"height\", function(d){return d.bbox.height})\n",
       "                              .style(\"fill\", \"white\")\n",
       "                              // .style(\"stroke\", \"black\");\n",
       "\n",
       "            const all_docs = Object.values(docs)                    \n",
       "\n",
       "            const docs_g = svg.append(\"g\")\n",
       "                      .attr(\"id\", \"docs\")\n",
       "                    .selectAll('g')\n",
       "                    .data(all_docs)\n",
       "                    .enter()\n",
       "                    .append('g')\n",
       "\n",
       "            const radiusScale = d3.scaleLinear().domain(d3.extent(all_docs, d=>d.count)).range([3,10])\n",
       "            docs_g.append('circle')\n",
       "                .attr('r', d=>radiusScale(d.count))\n",
       "                .attr('cx', d=>xScale(d.cx))\n",
       "                .attr('cy', d=>yScale(d.cy))\n",
       "                .style('fill', d => {\n",
       "                  console.log(d);\n",
       "                  if (d['docs'][0].trace == 'query')\n",
       "                    return '#d95f02'\n",
       "                  else return '#1b9e77'\n",
       "                })\n",
       "                .style('opacity', 0.5)\n",
       "                .on('mouseover', function(d) {\n",
       "                  let tip_text = d.docs.slice(0,10).map(t => t.title).join('<br>');\n",
       "                  if (d.docs.length > 10) {\n",
       "                    tip_text += `<br> (+ ${d.docs.length - 10} other documents)`\n",
       "                  }\n",
       "                  return tooltip.style(\"visibility\", \"visible\")\n",
       "                                .style(\"top\", yScale(d.cy) + \"px\")\n",
       "                                .style(\"left\", xScale(d.cx) + \"px\")\n",
       "                                .html(tip_text);\n",
       "                })\n",
       "                .on('mouseout', function(d) {\n",
       "                  return tooltip.style(\"visibility\", \"hidden\");\n",
       "                });\n",
       "\n",
       "\n",
       "            function wrap(text, width) {\n",
       "              text.each(function() {\n",
       "                  var text = d3.select(this),\n",
       "                      words = text.text().split(/\\s+/).reverse(),\n",
       "                      word,\n",
       "                      line = [],\n",
       "                      lineNumber = 0,\n",
       "                      lineHeight = 1.1, // ems\n",
       "                      x = text.attr(\"x\"),\n",
       "                      y = text.attr(\"y\"),\n",
       "                      dy = 0,\n",
       "                      tspan = text.text(null).append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", dy + \"em\");\n",
       "                  // console.log(text);\n",
       "                  while (word = words.pop()) {\n",
       "                    line.push(word);\n",
       "                    tspan.text(line.join(\" \"));\n",
       "                    if (tspan.node().getComputedTextLength() > width) {\n",
       "                      line.pop();\n",
       "                      tspan.text(line.join(\" \"));\n",
       "                      line = [word];\n",
       "                      console.log(line);\n",
       "                      tspan = text.append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", ++lineNumber * lineHeight + dy + \"em\").text(word);\n",
       "                    }\n",
       "                  }\n",
       "                });\n",
       "            }\n",
       "            \n",
       "            const docs_text = docs_g.append('text')\n",
       "                  .attr('class', 'doc-text')\n",
       "                  .text(d => d.docs.length > 1 ? `${d.docs.length} documents` : d.docs[0].title)\n",
       "                  .attr('x', d => xScale(d.cx))\n",
       "                  .attr('y', d => 8 + yScale(d.cy))\n",
       "                  .style('font-size', \"5px\")\n",
       "                  .style('text-anchor', \"middle\")\n",
       "                  .style('font-weight', \"light\")\n",
       "                  .call(wrap, 50);\n",
       "            \n",
       "          })\n",
       "        </script>\n",
       "      \n",
       "      "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython\n",
    "import IPython.display as display\n",
    "\n",
    "\n",
    "display.display(display.Javascript('window.path_data = %s' % json_results))\n",
    "\n",
    "display.display(IPython.core.display.HTML('''\n",
    "         <div id='vis'></div>\n",
    "         <style>\n",
    "           .container { width:100% !important; }\n",
    "           .vis-tooltip {\n",
    "              position: absolute;\n",
    "              z-index: 10;\n",
    "              visibility: hidden;\n",
    "              background-color: whitesmoke;\n",
    "              text-align: center;\n",
    "              padding: 4px;\n",
    "              border-radius: 4px;\n",
    "              font-weight: bold;\n",
    "              color: black;\n",
    "              pointer-events: none;\n",
    "          }\n",
    "         </style>\n",
    "         <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "         <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              \"d3\": \"https://d3js.org/d3.v5.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        <script>\n",
    "          \n",
    "          requirejs(['d3'], function(d3) {\n",
    "            const width = 1850,\n",
    "                  height = 1850;\n",
    "                  \n",
    "\n",
    "            const svg = d3.select('#vis').append('svg')\n",
    "                            .attr('id', 'vis-svg')\n",
    "                            .attr('width', width)\n",
    "                            .attr('height', height);\n",
    "            graph_json = window.path_data\n",
    "            \n",
    "            console.log(JSON.stringify(graph_json))\n",
    "            \n",
    "            const graph = graph_json['graph'];\n",
    "            const docs = graph_json['docs'];\n",
    "\n",
    "            const xScale = d3.scaleLinear().domain(d3.extent(graph.nodes, d=>d.x)).range([160, width-160])\n",
    "            const yScale = d3.scaleLinear().domain(d3.extent(graph.nodes, d=>d.y)).range([40, height-40])\n",
    "\n",
    "            const linkline = d3.line()\n",
    "                                  .x(d => xScale(d.x))\n",
    "                                  .y(d => yScale(d.y));\n",
    "\n",
    "            const docs_three = Object.keys(docs).filter(d=>d.split('+').length >= 2).map(d => docs[d])\n",
    "\n",
    "            const doc_lines_data = []\n",
    "            \n",
    "            const tooltip = d3.select(\"#vis\")\n",
    "                      .append(\"div\")\n",
    "                      .attr('class', 'vis-tooltip');\n",
    "\n",
    "            docs_three.forEach(doc => {\n",
    "              doc['docs'].forEach(d => {\n",
    "                d['token_indices_c'].forEach(t=> {\n",
    "                  const target_node = graph.nodes.filter(r => r.id == t)[0]\n",
    "                  const line_points = [\n",
    "                    {\n",
    "                      'x' : doc.cx,\n",
    "                      'y' : doc.cy \n",
    "                    },\n",
    "                    {\n",
    "                      'x' : target_node.x,\n",
    "                      'y' : target_node.y\n",
    "                    }\n",
    "                  ]\n",
    "                  doc_lines_data.push(line_points)\n",
    "                })\n",
    "              })\n",
    "            })\n",
    "\n",
    "\n",
    "            const doc_links = svg.append(\"g\")\n",
    "                            .attr(\"id\", \"doc_links\")\n",
    "                          .selectAll(\"line\")\n",
    "                          .data(doc_lines_data)\n",
    "                          .enter().append(\"path\")\n",
    "                            .attr(\"stroke-dasharray\", '5,5')\n",
    "                            .style(\"stroke\", \"black\")\n",
    "                            .attr(\"stroke-width\", 0.5)\n",
    "                            .attr(\"opacity\", 0.4)\n",
    "                            .attr(\"d\", d => linkline(d));\n",
    "\n",
    "\n",
    "            const links = svg.append(\"g\")\n",
    "                            .attr(\"id\", \"links\")\n",
    "                          .selectAll(\"line\")\n",
    "                          .data(graph.links)\n",
    "                          .enter().append(\"path\")\n",
    "                            .style(\"stroke\", \"black\")\n",
    "                            .attr(\"stroke-width\", 0.5)\n",
    "                            .attr(\"opacity\", 0.4)\n",
    "                            .attr(\"d\", d => linkline(graph.nodes.filter(b=>b.id == d.source || b.id == d.target)));\n",
    "\n",
    "\n",
    "            function getBB(selection) {\n",
    "                selection.each(function(d){d.bbox = this.getBBox();})\n",
    "            }\n",
    "\n",
    "            const nodes_g = svg.append(\"g\")\n",
    "                            .attr(\"id\", \"nodes\")\n",
    "                          .selectAll('g')\n",
    "                          .data(graph.nodes)\n",
    "                          .enter()\n",
    "                          .append('g');\n",
    "            nodes_g\n",
    "                  .append('text')\n",
    "                    .attr(\"class\", \"node\")\n",
    "                    .text(d=> d.keyword[0])\n",
    "                    .attr('x', d => xScale(d.x))\n",
    "                    .attr('y', d =>  yScale(d.y))\n",
    "                    .style('fill', d=>d.trace_color)\n",
    "                    .style('font-size', \"10px\")\n",
    "                    .style('font-weight', \"bold\")\n",
    "                    .style('text-anchor', \"middle\")\n",
    "                    .call(getBB);\n",
    "\n",
    "            nodes_g.insert(\"rect\", \"text\")\n",
    "                              .attr('x', d => xScale(d.x) - d.bbox.width/2)\n",
    "                              .attr('y', d => yScale(d.y) - 3*(d.bbox.height/4))\n",
    "                              .attr(\"width\", function(d){return d.bbox.width})\n",
    "                              .attr(\"height\", function(d){return d.bbox.height})\n",
    "                              .style(\"fill\", \"white\")\n",
    "                              // .style(\"stroke\", \"black\");\n",
    "\n",
    "            const all_docs = Object.values(docs)                    \n",
    "\n",
    "            const docs_g = svg.append(\"g\")\n",
    "                      .attr(\"id\", \"docs\")\n",
    "                    .selectAll('g')\n",
    "                    .data(all_docs)\n",
    "                    .enter()\n",
    "                    .append('g')\n",
    "\n",
    "            const radiusScale = d3.scaleLinear().domain(d3.extent(all_docs, d=>d.count)).range([3,10])\n",
    "            docs_g.append('circle')\n",
    "                .attr('r', d=>radiusScale(d.count))\n",
    "                .attr('cx', d=>xScale(d.cx))\n",
    "                .attr('cy', d=>yScale(d.cy))\n",
    "                .style('fill', d => {\n",
    "                  console.log(d);\n",
    "                  if (d['docs'][0].trace == 'query')\n",
    "                    return '#d95f02'\n",
    "                  else return '#1b9e77'\n",
    "                })\n",
    "                .style('opacity', 0.5)\n",
    "                .on('mouseover', function(d) {\n",
    "                  let tip_text = d.docs.slice(0,10).map(t => t.title).join('<br>');\n",
    "                  if (d.docs.length > 10) {\n",
    "                    tip_text += `<br> (+ ${d.docs.length - 10} other documents)`\n",
    "                  }\n",
    "                  return tooltip.style(\"visibility\", \"visible\")\n",
    "                                .style(\"top\", yScale(d.cy) + \"px\")\n",
    "                                .style(\"left\", xScale(d.cx) + \"px\")\n",
    "                                .html(tip_text);\n",
    "                })\n",
    "                .on('mouseout', function(d) {\n",
    "                  return tooltip.style(\"visibility\", \"hidden\");\n",
    "                });\n",
    "\n",
    "\n",
    "            function wrap(text, width) {\n",
    "              text.each(function() {\n",
    "                  var text = d3.select(this),\n",
    "                      words = text.text().split(/\\s+/).reverse(),\n",
    "                      word,\n",
    "                      line = [],\n",
    "                      lineNumber = 0,\n",
    "                      lineHeight = 1.1, // ems\n",
    "                      x = text.attr(\"x\"),\n",
    "                      y = text.attr(\"y\"),\n",
    "                      dy = 0,\n",
    "                      tspan = text.text(null).append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", dy + \"em\");\n",
    "                  // console.log(text);\n",
    "                  while (word = words.pop()) {\n",
    "                    line.push(word);\n",
    "                    tspan.text(line.join(\" \"));\n",
    "                    if (tspan.node().getComputedTextLength() > width) {\n",
    "                      line.pop();\n",
    "                      tspan.text(line.join(\" \"));\n",
    "                      line = [word];\n",
    "                      console.log(line);\n",
    "                      tspan = text.append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", ++lineNumber * lineHeight + dy + \"em\").text(word);\n",
    "                    }\n",
    "                  }\n",
    "                });\n",
    "            }\n",
    "            \n",
    "            const docs_text = docs_g.append('text')\n",
    "                  .attr('class', 'doc-text')\n",
    "                  .text(d => d.docs.length > 1 ? `${d.docs.length} documents` : d.docs[0].title)\n",
    "                  .attr('x', d => xScale(d.cx))\n",
    "                  .attr('y', d => 8 + yScale(d.cy))\n",
    "                  .style('font-size', \"5px\")\n",
    "                  .style('text-anchor', \"middle\")\n",
    "                  .style('font-weight', \"light\")\n",
    "                  .call(wrap, 50);\n",
    "            \n",
    "          })\n",
    "        </script>\n",
    "      \n",
    "      '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYyZsYyK7Jn-"
   },
   "source": [
    "# Scratchpad\n",
    "If you want to add your own experiments or have a closer look at the data structures this is the right place to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNzp8yUN7Rsh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<div class=\"cite2c-biblio\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "5825190/2GKEGQL9": {
     "DOI": "10.5281/zenodo.1344341",
     "URL": "https://doi.org/10.5281/zenodo.1344341",
     "author": [
      {
       "family": "Schöch",
       "given": "Christof"
      }
     ],
     "id": "5825190/2GKEGQL9",
     "issued": {
      "year": 2018
     },
     "note": "Citation Key: christof_schoch_2018_1344341",
     "title": "Abstracts from the Digital Humanities conference in Mexico D.F 2018 (DH2018)",
     "type": "article-journal"
    },
    "5825190/2M3GJCKB": {
     "id": "5825190/2M3GJCKB",
     "title": "Huang and Lai - 2006 - Clustering graphs for visualization via node simil.pdf",
     "type": "article"
    },
    "5825190/3CIKKD6P": {
     "abstract": "Graphs (networks) are very common data structures which are handled in computers. Diagrams are widely used to represent the graph structures visually in many information systems. In order to automatically draw the diagrams which are, for example, state graphs, data-flow graphs, Petri nets, and entity-relationship diagrams, basic graph drawing algorithms are required.",
     "author": [
      {
       "family": "Kamada",
       "given": "Tomihisa"
      },
      {
       "family": "Kawai",
       "given": "Satoru"
      }
     ],
     "container-title": "Information Processing Letters",
     "id": "5825190/3CIKKD6P",
     "issued": {
      "year": 1989
     },
     "title": "An algorithm for drawing general undirected graphs",
     "type": "article-journal"
    },
    "5825190/AGWC3HVT": {
     "URL": "https://www.transacl.org/ojs/index.php/tacl/article/view/570",
     "abstract": "Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.",
     "accessed": {
      "day": 29,
      "month": 1,
      "year": 2019
     },
     "author": [
      {
       "family": "Levy",
       "given": "Omer"
      },
      {
       "family": "Goldberg",
       "given": "Yoav"
      },
      {
       "family": "Dagan",
       "given": "Ido"
      }
     ],
     "container-title": "Transactions of the Association for Computational Linguistics",
     "id": "5825190/AGWC3HVT",
     "issue": "0",
     "issued": {
      "day": 4,
      "month": 5,
      "year": 2015
     },
     "language": "en",
     "page": "211-225",
     "page-first": "211",
     "title": "Improving Distributional Similarity with Lessons Learned from Word Embeddings",
     "type": "article-journal",
     "volume": "3"
    },
    "5825190/B4LPB8XA": {
     "DOI": "10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9",
     "URL": "https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-4571%28199009%2941%3A6%3C391%3A%3AAID-ASI1%3E3.0.CO%3B2-9",
     "abstract": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (“semantic structure”) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. Initial tests find this completely automatic method for retrieval to be promising. © 1990 John Wiley & Sons, Inc.",
     "accessed": {
      "day": 3,
      "month": 4,
      "year": 2019
     },
     "author": [
      {
       "family": "Deerwester",
       "given": "Scott"
      },
      {
       "family": "Dumais",
       "given": "Susan T."
      },
      {
       "family": "Furnas",
       "given": "George W."
      },
      {
       "family": "Landauer",
       "given": "Thomas K."
      },
      {
       "family": "Harshman",
       "given": "Richard"
      }
     ],
     "container-title": "Journal of the American Society for Information Science",
     "id": "5825190/B4LPB8XA",
     "issue": "6",
     "issued": {
      "year": 1990
     },
     "language": "en",
     "page": "391-407",
     "page-first": "391",
     "title": "Indexing by latent semantic analysis",
     "type": "article-journal",
     "volume": "41"
    },
    "5825190/EPG46MXF": {
     "URL": "https://dhs.stanford.edu/algorithmic-literacy/digital-literacy-and-digital-citizenship/",
     "accessed": {
      "day": 26,
      "month": 9,
      "year": 2018
     },
     "author": [
      {
       "family": "Meeks",
       "given": "Elijah"
      }
     ],
     "id": "5825190/EPG46MXF",
     "issued": {
      "year": 2013
     },
     "language": "en-US",
     "title": "Digital Literacy and Digital Citizenship | Digital Humanities Specialist",
     "type": "webpage"
    },
    "5825190/GEINZ3ZS": {
     "URL": "http://dl.acm.org/citation.cfm?id=89086.89095",
     "abstract": "The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor. ) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand subjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words.",
     "accessed": {
      "day": 29,
      "month": 1,
      "year": 2019
     },
     "author": [
      {
       "family": "Church",
       "given": "Kenneth Ward"
      },
      {
       "family": "Hanks",
       "given": "Patrick"
      }
     ],
     "container-title": "Comput. Linguist.",
     "id": "5825190/GEINZ3ZS",
     "issue": "1",
     "issued": {
      "month": 3,
      "year": 1990
     },
     "page": "22–29",
     "page-first": "22",
     "title": "Word Association Norms, Mutual Information, and Lexicography",
     "type": "article-journal",
     "volume": "16"
    },
    "5825190/GGZM7TH4": {
     "abstract": "In the context of a larger discussion about how to incorporate Humanities values into evaluations of visualization projects in Digital Humanities, this position paper uses the Poem Viewer and POEMAGE collaborations between computer scientists and poets to consider a specific case in which working with computer scientists and computers on poetry visualization tools helped one poet/poetry scholar refine and deepen her thinking about poetry in both its sonic and figurative dimensions as she continued to engage in her primary work of close reading and textual analysis. Based on this case, it then argues that working with the computer may benefit close readers of poetry not only by showing them relationships in poems they might not otherwise have noticed, but also by teaching them new, more precise ways of approaching and thinking about the operations of poems, including metaphor. It concludes by suggesting a few concrete ways of incorporating these kinds of scholarly activities not subject to the usual kinds of measurement into evaluations.",
     "author": [
      {
       "family": "Coles",
       "given": "Katharine"
      }
     ],
     "container-title": "Proc. 2nd Workshop on Visualization for the Digital Humanities (VIS4DH)",
     "event": "2nd Workshop on Visualization for the Digital Humanities (VIS4DH)",
     "id": "5825190/GGZM7TH4",
     "issued": {
      "year": 2017
     },
     "title": "Think Like a Machine (or not)",
     "type": "paper-conference"
    },
    "5825190/NKZVXPYC": {
     "DOI": "10.1109/TVCG.2016.2615308",
     "abstract": "We have created and made available to all a dataset with information about every paper that has appeared at the IEEE Visualization (VIS) set of conferences: InfoVis, SciVis, VAST, and Vis. The information about each paper includes its title, abstract, authors, and citations to other papers in the conference series, among many other attributes. This article describes the motivation for creating the dataset, as well as our process of coalescing and cleaning the data, and a set of three visualizations we created to facilitate exploration of the data. This data is meant to be useful to the broad data visualization community to help understand the evolution of the field and as an example document collection for text data visualization research.",
     "author": [
      {
       "family": "Isenberg",
       "given": "P."
      },
      {
       "family": "Heimerl",
       "given": "F."
      },
      {
       "family": "Koch",
       "given": "S."
      },
      {
       "family": "Isenberg",
       "given": "T."
      },
      {
       "family": "Xu",
       "given": "P."
      },
      {
       "family": "Stolper",
       "given": "C. D."
      },
      {
       "family": "Sedlmair",
       "given": "M."
      },
      {
       "family": "Chen",
       "given": "J."
      },
      {
       "family": "Möller",
       "given": "T."
      },
      {
       "family": "Stasko",
       "given": "J."
      }
     ],
     "container-title": "IEEE Transactions on Visualization and Computer Graphics",
     "id": "5825190/NKZVXPYC",
     "issue": "9",
     "issued": {
      "month": 9,
      "year": 2017
     },
     "page": "2199-2206",
     "page-first": "2199",
     "shortTitle": "Vispubdata.org",
     "title": "Vispubdata.org: A Metadata Collection About IEEE Visualization (VIS) Publications",
     "title-short": "Vispubdata.org",
     "type": "article-journal",
     "volume": "23"
    },
    "5825190/SAAU4NU2": {
     "DOI": "10.1080/17470218.2015.1038280",
     "URL": "https://doi.org/10.1080/17470218.2015.1038280",
     "abstract": "In distributional semantics models (DSMs) such as latent semantic analysis (LSA), words are represented as vectors in a high-dimensional vector space. This allows for computing word similarities as the cosine of the angle between two such vectors. In two experiments, we investigated whether LSA cosine similarities predict priming effects, in that higher cosine similarities are associated with shorter reaction times (RTs). Critically, we applied a pseudo-random procedure in generating the item material to ensure that we directly manipulated LSA cosines as an independent variable. We employed two lexical priming experiments with lexical decision tasks (LDTs). In Experiment 1 we presented participants with 200 different prime words, each paired with one unique target. We found a significant effect of cosine similarities on RTs. The same was true for Experiment 2, where we reversed the prime-target order (primes of Experiment 1 were targets in Experiment 2, and vice versa). The results of these experiments confirm that LSA cosine similarities can predict priming effects, supporting the view that they are psychologically relevant. The present study thereby provides evidence for qualifying LSA cosine similarities not only as a linguistic measure, but also as a cognitive similarity measure. However, it is also shown that other DSMs can outperform LSA as a predictor of priming effects.",
     "accessed": {
      "day": 3,
      "month": 4,
      "year": 2019
     },
     "author": [
      {
       "family": "Günther",
       "given": "Fritz"
      },
      {
       "family": "Dudschig",
       "given": "Carolin"
      },
      {
       "family": "Kaup",
       "given": "Barbara"
      }
     ],
     "container-title": "The Quarterly Journal of Experimental Psychology",
     "id": "5825190/SAAU4NU2",
     "issue": "4",
     "issued": {
      "day": 2,
      "month": 4,
      "year": 2016
     },
     "note": "PMID: 25952009",
     "page": "626-653",
     "page-first": "626",
     "shortTitle": "Latent semantic analysis cosines as a cognitive similarity measure",
     "title": "Latent semantic analysis cosines as a cognitive similarity measure: Evidence from priming studies",
     "title-short": "Latent semantic analysis cosines as a cognitive similarity measure",
     "type": "article-journal",
     "volume": "69"
    },
    "5825190/SD9XSNXL": {
     "DOI": "10.1037/0033-295X.104.2.211",
     "abstract": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena and problems are sketched. (PsycINFO Database Record (c) 2016 APA, all rights reserved)",
     "author": [
      {
       "family": "Landauer",
       "given": "Thomas K."
      },
      {
       "family": "Dumais",
       "given": "Susan T."
      }
     ],
     "container-title": "Psychological Review",
     "id": "5825190/SD9XSNXL",
     "issue": "2",
     "issued": {
      "year": 1997
     },
     "page": "211-240",
     "page-first": "211",
     "shortTitle": "A solution to Plato's problem",
     "title": "A solution to Plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge",
     "title-short": "A solution to Plato's problem",
     "type": "article-journal",
     "volume": "104"
    },
    "5825190/SFVYGKHS": {
     "abstract": "The value of a visualization evolved in a digital humanities project is per se not evenly high for both involved research fields. When an approach is too complex – which counts as a strong argument for a publication in a visualization realm – it might get invaluable for humanities scholars due to problems of comprehension. On the other hand, if a clean, easily comprehensible visualization is valuable for a humanities scholar, the missing novelty most likely impedes a computer science publication. My own digital humanities background has shown that it is indeed a balancing act to generate beneficial research results for both the visualization and the digital humanities fields. To find out how visualizations are used as means to communicate humanities matters and to assess the impact of the visualization community to the digital humanities field, I surveyed the long papers of the last four annual digital humanities conferences, discovering that visualization scholars are rarely involved in collaborations that produce valuable digital humanities results, in other words, it seems hard to walk the tightrope of generating valuable research for both fields. Derived from my own digital humanities experiences, I suggest a methodology how to design a digital humanities project to overcome this issue.",
     "author": [
      {
       "family": "Jänicke",
       "given": "Stefan"
      }
     ],
     "container-title": "Proc. 1st Workshop on Visualization for the Digital Humanities (VIS4DH)",
     "event": "1st Workshop on Visualization for the Digital Humanities",
     "id": "5825190/SFVYGKHS",
     "issued": {
      "year": 2016
     },
     "title": "Valuable Research for Visualization and Digital Humanities: A Balancing Act",
     "type": "paper-conference"
    },
    "5825190/U2RP32HP": {
     "URL": "http://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf",
     "author": [
      {
       "family": "Chang",
       "given": "Jonathan"
      },
      {
       "family": "Gerrish",
       "given": "Sean"
      },
      {
       "family": "Wang",
       "given": "Chong"
      },
      {
       "family": "Boyd-graber",
       "given": "Jordan L."
      },
      {
       "family": "Blei",
       "given": "David M."
      }
     ],
     "container-title": "Advances in Neural Information Processing Systems 22",
     "editor": [
      {
       "family": "Bengio",
       "given": "Y."
      },
      {
       "family": "Schuurmans",
       "given": "D."
      },
      {
       "family": "Lafferty",
       "given": "J. D."
      },
      {
       "family": "Williams",
       "given": "C. K. I."
      },
      {
       "family": "Culotta",
       "given": "A."
      }
     ],
     "id": "5825190/U2RP32HP",
     "issued": {
      "year": 2009
     },
     "note": "Citation Key: NIPS2009_3700",
     "page": "288-296",
     "page-first": "288",
     "publisher": "Curran Associates, Inc.",
     "title": "Reading Tea Leaves: How Humans Interpret Topic Models",
     "type": "chapter"
    },
    "5825190/U2ZY3SKR": {
     "id": "5825190/U2ZY3SKR",
     "title": "Isenberg et al. - 2017 - Vispubdata.org A Metadata Collection About IEEE V.pdf",
     "type": "article"
    },
    "5825190/WEDH9C6G": {
     "URL": "http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf",
     "accessed": {
      "day": 23,
      "month": 1,
      "year": 2019
     },
     "author": [
      {
       "family": "Levy",
       "given": "Omer"
      },
      {
       "family": "Goldberg",
       "given": "Yoav"
      }
     ],
     "container-title": "Advances in Neural Information Processing Systems 27",
     "editor": [
      {
       "family": "Ghahramani",
       "given": "Z."
      },
      {
       "family": "Welling",
       "given": "M."
      },
      {
       "family": "Cortes",
       "given": "C."
      },
      {
       "family": "Lawrence",
       "given": "N. D."
      },
      {
       "family": "Weinberger",
       "given": "K. Q."
      }
     ],
     "id": "5825190/WEDH9C6G",
     "issued": {
      "year": 2014
     },
     "page": "2177–2185",
     "page-first": "2177",
     "publisher": "Curran Associates, Inc.",
     "title": "Neural Word Embedding as Implicit Matrix Factorization",
     "type": "chapter"
    },
    "5825190/YJCC8EDY": {
     "DOI": "10.1007/BF02812438",
     "URL": "https://doi.org/10.1007/BF02812438",
     "abstract": "Standard psychological scaling methods have been widely used as knowledge elicitation tools to uncover structural characteristics of a given domain. However, these methods traditionally rely on relatedness ratings from human experts, which is often time-consuming and tedious. We describe an integrated approach to knowledge elicitation and representation using Latent Semantic Analysis and Pathfinder Network Scaling techniques. The semantic structure of a subject domain can be automatically characterised from a collection of published documents in the domain. The method is illustrated with an example of organising a digital library in accordance to latent semantic structures.",
     "accessed": {
      "day": 3,
      "month": 4,
      "year": 2019
     },
     "author": [
      {
       "family": "Chen",
       "given": "Chaomei"
      }
     ],
     "container-title": "AI & SOCIETY",
     "container-title-short": "AI & Soc",
     "id": "5825190/YJCC8EDY",
     "issue": "1",
     "issued": {
      "day": 1,
      "month": 3,
      "year": 1997
     },
     "journalAbbreviation": "AI & Soc",
     "language": "en",
     "page": "48-62",
     "page-first": "48",
     "shortTitle": "Tracking latent domain structures",
     "title": "Tracking latent domain structures: An integration of pathfinder and Latent Semantic Analysis",
     "title-short": "Tracking latent domain structures",
     "type": "article-journal",
     "volume": "11"
    },
    "undefined": {
     "DOI": "10.1080/17470218.2015.1038280",
     "URL": "https://doi.org/10.1080/17470218.2015.1038280",
     "abstract": "In distributional semantics models (DSMs) such as latent semantic analysis (LSA), words are represented as vectors in a high-dimensional vector space. This allows for computing word similarities as the cosine of the angle between two such vectors. In two experiments, we investigated whether LSA cosine similarities predict priming effects, in that higher cosine similarities are associated with shorter reaction times (RTs). Critically, we applied a pseudo-random procedure in generating the item material to ensure that we directly manipulated LSA cosines as an independent variable. We employed two lexical priming experiments with lexical decision tasks (LDTs). In Experiment 1 we presented participants with 200 different prime words, each paired with one unique target. We found a significant effect of cosine similarities on RTs. The same was true for Experiment 2, where we reversed the prime-target order (primes of Experiment 1 were targets in Experiment 2, and vice versa). The results of these experiments confirm that LSA cosine similarities can predict priming effects, supporting the view that they are psychologically relevant. The present study thereby provides evidence for qualifying LSA cosine similarities not only as a linguistic measure, but also as a cognitive similarity measure. However, it is also shown that other DSMs can outperform LSA as a predictor of priming effects.",
     "accessed": {
      "day": 3,
      "month": 4,
      "year": 2019
     },
     "author": [
      {
       "family": "Günther",
       "given": "Fritz"
      },
      {
       "family": "Dudschig",
       "given": "Carolin"
      },
      {
       "family": "Kaup",
       "given": "Barbara"
      }
     ],
     "container-title": "The Quarterly Journal of Experimental Psychology",
     "id": "undefined",
     "issue": "4",
     "issued": {
      "day": 2,
      "month": 4,
      "year": 2016
     },
     "note": "PMID: 25952009",
     "page": "626-653",
     "page-first": "626",
     "shortTitle": "Latent semantic analysis cosines as a cognitive similarity measure",
     "title": "Latent semantic analysis cosines as a cognitive similarity measure: Evidence from priming studies",
     "title-short": "Latent semantic analysis cosines as a cognitive similarity measure",
     "type": "article-journal",
     "volume": "69"
    }
   }
  },
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "keywords-vis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "keywords-vis",
   "language": "python",
   "name": "keywords-vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
